{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69652f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\noton\\miniconda3\\envs\\Deep2\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipped loading modules with pytorch-geometric dependency, missing a dependency. No module named 'dgl'\n",
      "Skipped loading modules with transformers dependency. No module named 'transformers'\n",
      "cannot import name 'HuggingFaceModel' from 'deepchem.models.torch_models' (C:\\Users\\noton\\miniconda3\\envs\\Deep2\\lib\\site-packages\\deepchem\\models\\torch_models\\__init__.py)\n",
      "Skipped loading some Jax models, missing a dependency. No module named 'jax'\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import tensorflow as tf\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import deepchem as dc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, global_max_pool\n",
    "from torch_geometric.data import Batch, Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66bffaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GCNConv(30, 256)\n",
    "        self.conv2 = GCNConv(256, 256)\n",
    "        self.conv3 = GCNConv(256, 256)\n",
    "        self.conv4 = GCNConv(256, 256)\n",
    "        self.fc1 = nn.Linear(256, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 1)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv4(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = global_max_pool(x, data.batch)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "245051e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate(batch):\n",
    "    data_list, target_list = zip(*batch)\n",
    "    batch_data = Batch.from_data_list(data_list)\n",
    "    batch_target = torch.stack(target_list)\n",
    "    return batch_data, batch_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be45c11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_statistics(group):\n",
    "    r2_test = group['r2_test']\n",
    "    r2_test_dict = {f'run{i}': r2_test_val for i, r2_test_val in enumerate(r2_test)}\n",
    "    return pd.Series({\n",
    "        **r2_test_dict, \n",
    "        'r2_test_mean': np.mean(r2_test),\n",
    "        'r2_test_max': np.max(r2_test),\n",
    "        'r2_test_min': np.min(r2_test),\n",
    "        'r2_test_std': np.std(r2_test, ddof=0),\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53851fc9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "epochs = 100\n",
    "lr = 1e-2\n",
    "wd = 4e-4\n",
    "\n",
    "results = []\n",
    "for random_state in range(10):\n",
    "    torch.manual_seed(0)\n",
    "    \n",
    "    for dataset in [\"abcgg\", \"aatsc3d\", \"atsc3d\", \"kappa2\", \"peoevsa6\", \"bertzct\", \"ggi10\", \"vsaestate3\",\n",
    "                    \"atsc4i\", \"bcutp1l\", \"kappa3\", \"estatevsa3\", \"kier3\", \"aats8p\", \"kier2\", \"frnh0\"]:\n",
    "        torch.manual_seed(0)\n",
    "        \n",
    "        for t in [\"Yield_CO_s\"]:\n",
    "            torch.manual_seed(0)\n",
    "            df = pd.read_csv('data_Real/data_real.csv')\n",
    "            smiles = df[\"SMILES\"]\n",
    "            featurizer = dc.feat.MolGraphConvFeaturizer(use_edges=True)\n",
    "            X = featurizer.featurize(smiles)\n",
    "            \n",
    "            y = df[t]\n",
    "            data_train, data_test, target_train, target_test = train_test_split(X, y, test_size=0.5, random_state=random_state)\n",
    "\n",
    "            target_train = scaler.fit_transform(target_train.values.reshape(-1, 1)).flatten()\n",
    "            target_test = scaler.transform(target_test.values.reshape(-1, 1)).flatten()\n",
    "            \n",
    "            target_train = torch.tensor(target_train, dtype=torch.float32)\n",
    "            target_test = torch.tensor(target_test, dtype=torch.float32)\n",
    "\n",
    "            data_train_list = []\n",
    "            for graph_data in data_train:\n",
    "                node_features = torch.tensor(graph_data.node_features, dtype=torch.float32)\n",
    "                edge_index = torch.tensor(graph_data.edge_index, dtype=torch.long)\n",
    "                edge_features = torch.tensor(graph_data.edge_features, dtype=torch.float32)\n",
    "                data = Data(x=node_features, edge_index=edge_index, edge_attr=edge_features)\n",
    "                data_train_list.append(data)\n",
    "\n",
    "            data_test_list = []\n",
    "            for graph_data in data_test:\n",
    "                node_features = torch.tensor(graph_data.node_features, dtype=torch.float32)\n",
    "                edge_index = torch.tensor(graph_data.edge_index, dtype=torch.long)\n",
    "                edge_features = torch.tensor(graph_data.edge_features, dtype=torch.float32)\n",
    "                data = Data(x=node_features, edge_index=edge_index, edge_attr=edge_features)\n",
    "                data_test_list.append(data)\n",
    "\n",
    "            train_loader = DataLoader(list(zip(data_train_list, target_train)), batch_size=len(data_train_list), collate_fn=custom_collate)\n",
    "            test_loader = DataLoader(list(zip(data_test_list, target_test)), batch_size=len(data_test_list), collate_fn=custom_collate)\n",
    "\n",
    "            model = Net()\n",
    "            model.load_state_dict(torch.load(f'data_Random/model_{dataset}_sc.pth'))\n",
    "            model.fc3 = nn.Linear(128, 1)\n",
    "        \n",
    "            model.train()\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "            criterion = nn.MSELoss()\n",
    "        \n",
    "            for param in model.conv1.parameters():\n",
    "                param.requires_grad = False\n",
    "            for param in model.conv2.parameters():\n",
    "                param.requires_grad = False\n",
    "            for param in model.conv3.parameters():\n",
    "                param.requires_grad = False\n",
    "            for param in model.conv4.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "            device = torch.device('cpu')\n",
    "            model.to(device)\n",
    "            \n",
    "            # Replacing the head layer with a new one.\n",
    "            # Unfreezing FC layers.\n",
    "\n",
    "            for epoch in range(epochs):\n",
    "                for data, target in train_loader:\n",
    "                    data = data.to(device)\n",
    "                    target = target.to(device)\n",
    "                    optimizer.zero_grad()\n",
    "                    out = model(data)\n",
    "                    loss = criterion(out, target.view(-1, 1))\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            model.eval()\n",
    "            pred_train = []\n",
    "            for data, target in train_loader:\n",
    "                data = data.to(device)\n",
    "                with torch.no_grad():\n",
    "                    out = model(data)\n",
    "                pred_train.append(out.cpu().numpy())\n",
    "            pred_train = np.concatenate(pred_train)\n",
    "\n",
    "            pred_test = []\n",
    "            for data, target in test_loader:\n",
    "                data = data.to(device)\n",
    "                with torch.no_grad():\n",
    "                    out = model(data)\n",
    "                pred_test.append(out.cpu().numpy())\n",
    "            pred_test = np.concatenate(pred_test)\n",
    "\n",
    "            pred_train = scaler.inverse_transform(pred_train)\n",
    "            pred_test = scaler.inverse_transform(pred_test)\n",
    "            target_train = scaler.inverse_transform(target_train.numpy().reshape(-1, 1)).flatten()\n",
    "            target_test = scaler.inverse_transform(target_test.numpy().reshape(-1, 1)).flatten()\n",
    "\n",
    "            r2_test_score = metrics.r2_score(target_test, pred_test)\n",
    "            results.append({'source': dataset, 'target': t, 'r2_test': r2_test_score})\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "gen_results = results_df.groupby(['source', 'target']).apply(calculate_statistics).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "463235ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>source</th>\n",
       "      <td>aats8p</td>\n",
       "      <td>aatsc3d</td>\n",
       "      <td>abcgg</td>\n",
       "      <td>atsc3d</td>\n",
       "      <td>atsc4i</td>\n",
       "      <td>bcutp1l</td>\n",
       "      <td>bertzct</td>\n",
       "      <td>estatevsa3</td>\n",
       "      <td>frnh0</td>\n",
       "      <td>ggi10</td>\n",
       "      <td>kappa2</td>\n",
       "      <td>kappa3</td>\n",
       "      <td>kier2</td>\n",
       "      <td>kier3</td>\n",
       "      <td>peoevsa6</td>\n",
       "      <td>vsaestate3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>Yield_CO_s</td>\n",
       "      <td>Yield_CO_s</td>\n",
       "      <td>Yield_CO_s</td>\n",
       "      <td>Yield_CO_s</td>\n",
       "      <td>Yield_CO_s</td>\n",
       "      <td>Yield_CO_s</td>\n",
       "      <td>Yield_CO_s</td>\n",
       "      <td>Yield_CO_s</td>\n",
       "      <td>Yield_CO_s</td>\n",
       "      <td>Yield_CO_s</td>\n",
       "      <td>Yield_CO_s</td>\n",
       "      <td>Yield_CO_s</td>\n",
       "      <td>Yield_CO_s</td>\n",
       "      <td>Yield_CO_s</td>\n",
       "      <td>Yield_CO_s</td>\n",
       "      <td>Yield_CO_s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run0</th>\n",
       "      <td>0.737883</td>\n",
       "      <td>0.824573</td>\n",
       "      <td>0.766486</td>\n",
       "      <td>0.65414</td>\n",
       "      <td>0.648354</td>\n",
       "      <td>0.666878</td>\n",
       "      <td>0.812871</td>\n",
       "      <td>0.708539</td>\n",
       "      <td>0.780604</td>\n",
       "      <td>0.742882</td>\n",
       "      <td>0.790022</td>\n",
       "      <td>0.749074</td>\n",
       "      <td>0.784251</td>\n",
       "      <td>0.745903</td>\n",
       "      <td>0.672942</td>\n",
       "      <td>0.656078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run1</th>\n",
       "      <td>0.644403</td>\n",
       "      <td>0.42253</td>\n",
       "      <td>0.677805</td>\n",
       "      <td>0.636759</td>\n",
       "      <td>0.570834</td>\n",
       "      <td>0.380538</td>\n",
       "      <td>0.752107</td>\n",
       "      <td>0.519363</td>\n",
       "      <td>0.661028</td>\n",
       "      <td>0.495514</td>\n",
       "      <td>0.635522</td>\n",
       "      <td>0.730394</td>\n",
       "      <td>0.66172</td>\n",
       "      <td>0.591124</td>\n",
       "      <td>0.577949</td>\n",
       "      <td>0.183978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run2</th>\n",
       "      <td>0.445168</td>\n",
       "      <td>0.697523</td>\n",
       "      <td>0.630127</td>\n",
       "      <td>0.575098</td>\n",
       "      <td>0.650616</td>\n",
       "      <td>0.544755</td>\n",
       "      <td>0.722849</td>\n",
       "      <td>0.604855</td>\n",
       "      <td>0.474561</td>\n",
       "      <td>0.51054</td>\n",
       "      <td>0.61503</td>\n",
       "      <td>0.503681</td>\n",
       "      <td>0.670035</td>\n",
       "      <td>0.605824</td>\n",
       "      <td>0.47144</td>\n",
       "      <td>0.509625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run3</th>\n",
       "      <td>0.874689</td>\n",
       "      <td>0.842926</td>\n",
       "      <td>0.906072</td>\n",
       "      <td>0.883518</td>\n",
       "      <td>0.784121</td>\n",
       "      <td>0.445768</td>\n",
       "      <td>0.916402</td>\n",
       "      <td>0.749341</td>\n",
       "      <td>0.906964</td>\n",
       "      <td>0.901188</td>\n",
       "      <td>0.909007</td>\n",
       "      <td>0.888024</td>\n",
       "      <td>0.896391</td>\n",
       "      <td>0.892204</td>\n",
       "      <td>0.877925</td>\n",
       "      <td>0.837692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run4</th>\n",
       "      <td>0.56524</td>\n",
       "      <td>0.532852</td>\n",
       "      <td>0.70516</td>\n",
       "      <td>0.633393</td>\n",
       "      <td>0.586576</td>\n",
       "      <td>0.380654</td>\n",
       "      <td>0.730177</td>\n",
       "      <td>0.585977</td>\n",
       "      <td>0.715552</td>\n",
       "      <td>0.472933</td>\n",
       "      <td>0.687633</td>\n",
       "      <td>0.693222</td>\n",
       "      <td>0.729277</td>\n",
       "      <td>0.745968</td>\n",
       "      <td>0.627897</td>\n",
       "      <td>0.515997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run5</th>\n",
       "      <td>0.718633</td>\n",
       "      <td>0.721736</td>\n",
       "      <td>0.809933</td>\n",
       "      <td>0.741582</td>\n",
       "      <td>0.664792</td>\n",
       "      <td>0.690733</td>\n",
       "      <td>0.825206</td>\n",
       "      <td>0.718724</td>\n",
       "      <td>0.778386</td>\n",
       "      <td>0.761045</td>\n",
       "      <td>0.755107</td>\n",
       "      <td>0.770087</td>\n",
       "      <td>0.787244</td>\n",
       "      <td>0.797806</td>\n",
       "      <td>0.674449</td>\n",
       "      <td>0.668439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run6</th>\n",
       "      <td>0.739372</td>\n",
       "      <td>0.648539</td>\n",
       "      <td>0.727015</td>\n",
       "      <td>0.640586</td>\n",
       "      <td>0.692964</td>\n",
       "      <td>0.417343</td>\n",
       "      <td>0.77381</td>\n",
       "      <td>0.71522</td>\n",
       "      <td>0.703401</td>\n",
       "      <td>0.696358</td>\n",
       "      <td>0.780072</td>\n",
       "      <td>0.835987</td>\n",
       "      <td>0.766005</td>\n",
       "      <td>0.800934</td>\n",
       "      <td>0.705403</td>\n",
       "      <td>0.61859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run7</th>\n",
       "      <td>0.808368</td>\n",
       "      <td>0.675549</td>\n",
       "      <td>0.773156</td>\n",
       "      <td>0.736143</td>\n",
       "      <td>0.725398</td>\n",
       "      <td>0.686231</td>\n",
       "      <td>0.806671</td>\n",
       "      <td>0.73755</td>\n",
       "      <td>0.746487</td>\n",
       "      <td>0.754852</td>\n",
       "      <td>0.7346</td>\n",
       "      <td>0.798533</td>\n",
       "      <td>0.778601</td>\n",
       "      <td>0.80472</td>\n",
       "      <td>0.729948</td>\n",
       "      <td>0.656917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run8</th>\n",
       "      <td>0.819029</td>\n",
       "      <td>0.750229</td>\n",
       "      <td>0.779711</td>\n",
       "      <td>0.772824</td>\n",
       "      <td>0.760442</td>\n",
       "      <td>0.582257</td>\n",
       "      <td>0.827801</td>\n",
       "      <td>0.756331</td>\n",
       "      <td>0.800168</td>\n",
       "      <td>0.768209</td>\n",
       "      <td>0.802872</td>\n",
       "      <td>0.828733</td>\n",
       "      <td>0.777343</td>\n",
       "      <td>0.788083</td>\n",
       "      <td>0.795914</td>\n",
       "      <td>0.647061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run9</th>\n",
       "      <td>0.627749</td>\n",
       "      <td>0.579241</td>\n",
       "      <td>0.759429</td>\n",
       "      <td>0.748238</td>\n",
       "      <td>0.675541</td>\n",
       "      <td>0.313848</td>\n",
       "      <td>0.82959</td>\n",
       "      <td>0.473476</td>\n",
       "      <td>0.512725</td>\n",
       "      <td>0.742046</td>\n",
       "      <td>0.687594</td>\n",
       "      <td>0.679469</td>\n",
       "      <td>0.657165</td>\n",
       "      <td>0.693268</td>\n",
       "      <td>0.724218</td>\n",
       "      <td>0.400136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2_test_mean</th>\n",
       "      <td>0.698054</td>\n",
       "      <td>0.66957</td>\n",
       "      <td>0.753489</td>\n",
       "      <td>0.702228</td>\n",
       "      <td>0.675964</td>\n",
       "      <td>0.5109</td>\n",
       "      <td>0.799748</td>\n",
       "      <td>0.656938</td>\n",
       "      <td>0.707988</td>\n",
       "      <td>0.684557</td>\n",
       "      <td>0.739746</td>\n",
       "      <td>0.74772</td>\n",
       "      <td>0.750803</td>\n",
       "      <td>0.746583</td>\n",
       "      <td>0.685809</td>\n",
       "      <td>0.569451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2_test_max</th>\n",
       "      <td>0.874689</td>\n",
       "      <td>0.842926</td>\n",
       "      <td>0.906072</td>\n",
       "      <td>0.883518</td>\n",
       "      <td>0.784121</td>\n",
       "      <td>0.690733</td>\n",
       "      <td>0.916402</td>\n",
       "      <td>0.756331</td>\n",
       "      <td>0.906964</td>\n",
       "      <td>0.901188</td>\n",
       "      <td>0.909007</td>\n",
       "      <td>0.888024</td>\n",
       "      <td>0.896391</td>\n",
       "      <td>0.892204</td>\n",
       "      <td>0.877925</td>\n",
       "      <td>0.837692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2_test_min</th>\n",
       "      <td>0.445168</td>\n",
       "      <td>0.42253</td>\n",
       "      <td>0.630127</td>\n",
       "      <td>0.575098</td>\n",
       "      <td>0.570834</td>\n",
       "      <td>0.313848</td>\n",
       "      <td>0.722849</td>\n",
       "      <td>0.473476</td>\n",
       "      <td>0.474561</td>\n",
       "      <td>0.472933</td>\n",
       "      <td>0.61503</td>\n",
       "      <td>0.503681</td>\n",
       "      <td>0.657165</td>\n",
       "      <td>0.591124</td>\n",
       "      <td>0.47144</td>\n",
       "      <td>0.183978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2_test_std</th>\n",
       "      <td>0.122936</td>\n",
       "      <td>0.123469</td>\n",
       "      <td>0.071923</td>\n",
       "      <td>0.086003</td>\n",
       "      <td>0.064915</td>\n",
       "      <td>0.133952</td>\n",
       "      <td>0.054635</td>\n",
       "      <td>0.097532</td>\n",
       "      <td>0.124378</td>\n",
       "      <td>0.135044</td>\n",
       "      <td>0.083008</td>\n",
       "      <td>0.102277</td>\n",
       "      <td>0.07003</td>\n",
       "      <td>0.088718</td>\n",
       "      <td>0.106806</td>\n",
       "      <td>0.170011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0           1           2           3           4   \\\n",
       "source            aats8p     aatsc3d       abcgg      atsc3d      atsc4i   \n",
       "target        Yield_CO_s  Yield_CO_s  Yield_CO_s  Yield_CO_s  Yield_CO_s   \n",
       "run0            0.737883    0.824573    0.766486     0.65414    0.648354   \n",
       "run1            0.644403     0.42253    0.677805    0.636759    0.570834   \n",
       "run2            0.445168    0.697523    0.630127    0.575098    0.650616   \n",
       "run3            0.874689    0.842926    0.906072    0.883518    0.784121   \n",
       "run4             0.56524    0.532852     0.70516    0.633393    0.586576   \n",
       "run5            0.718633    0.721736    0.809933    0.741582    0.664792   \n",
       "run6            0.739372    0.648539    0.727015    0.640586    0.692964   \n",
       "run7            0.808368    0.675549    0.773156    0.736143    0.725398   \n",
       "run8            0.819029    0.750229    0.779711    0.772824    0.760442   \n",
       "run9            0.627749    0.579241    0.759429    0.748238    0.675541   \n",
       "r2_test_mean    0.698054     0.66957    0.753489    0.702228    0.675964   \n",
       "r2_test_max     0.874689    0.842926    0.906072    0.883518    0.784121   \n",
       "r2_test_min     0.445168     0.42253    0.630127    0.575098    0.570834   \n",
       "r2_test_std     0.122936    0.123469    0.071923    0.086003    0.064915   \n",
       "\n",
       "                      5           6           7           8           9   \\\n",
       "source           bcutp1l     bertzct  estatevsa3       frnh0       ggi10   \n",
       "target        Yield_CO_s  Yield_CO_s  Yield_CO_s  Yield_CO_s  Yield_CO_s   \n",
       "run0            0.666878    0.812871    0.708539    0.780604    0.742882   \n",
       "run1            0.380538    0.752107    0.519363    0.661028    0.495514   \n",
       "run2            0.544755    0.722849    0.604855    0.474561     0.51054   \n",
       "run3            0.445768    0.916402    0.749341    0.906964    0.901188   \n",
       "run4            0.380654    0.730177    0.585977    0.715552    0.472933   \n",
       "run5            0.690733    0.825206    0.718724    0.778386    0.761045   \n",
       "run6            0.417343     0.77381     0.71522    0.703401    0.696358   \n",
       "run7            0.686231    0.806671     0.73755    0.746487    0.754852   \n",
       "run8            0.582257    0.827801    0.756331    0.800168    0.768209   \n",
       "run9            0.313848     0.82959    0.473476    0.512725    0.742046   \n",
       "r2_test_mean      0.5109    0.799748    0.656938    0.707988    0.684557   \n",
       "r2_test_max     0.690733    0.916402    0.756331    0.906964    0.901188   \n",
       "r2_test_min     0.313848    0.722849    0.473476    0.474561    0.472933   \n",
       "r2_test_std     0.133952    0.054635    0.097532    0.124378    0.135044   \n",
       "\n",
       "                      10          11          12          13          14  \\\n",
       "source            kappa2      kappa3       kier2       kier3    peoevsa6   \n",
       "target        Yield_CO_s  Yield_CO_s  Yield_CO_s  Yield_CO_s  Yield_CO_s   \n",
       "run0            0.790022    0.749074    0.784251    0.745903    0.672942   \n",
       "run1            0.635522    0.730394     0.66172    0.591124    0.577949   \n",
       "run2             0.61503    0.503681    0.670035    0.605824     0.47144   \n",
       "run3            0.909007    0.888024    0.896391    0.892204    0.877925   \n",
       "run4            0.687633    0.693222    0.729277    0.745968    0.627897   \n",
       "run5            0.755107    0.770087    0.787244    0.797806    0.674449   \n",
       "run6            0.780072    0.835987    0.766005    0.800934    0.705403   \n",
       "run7              0.7346    0.798533    0.778601     0.80472    0.729948   \n",
       "run8            0.802872    0.828733    0.777343    0.788083    0.795914   \n",
       "run9            0.687594    0.679469    0.657165    0.693268    0.724218   \n",
       "r2_test_mean    0.739746     0.74772    0.750803    0.746583    0.685809   \n",
       "r2_test_max     0.909007    0.888024    0.896391    0.892204    0.877925   \n",
       "r2_test_min      0.61503    0.503681    0.657165    0.591124     0.47144   \n",
       "r2_test_std     0.083008    0.102277     0.07003    0.088718    0.106806   \n",
       "\n",
       "                      15  \n",
       "source        vsaestate3  \n",
       "target        Yield_CO_s  \n",
       "run0            0.656078  \n",
       "run1            0.183978  \n",
       "run2            0.509625  \n",
       "run3            0.837692  \n",
       "run4            0.515997  \n",
       "run5            0.668439  \n",
       "run6             0.61859  \n",
       "run7            0.656917  \n",
       "run8            0.647061  \n",
       "run9            0.400136  \n",
       "r2_test_mean    0.569451  \n",
       "r2_test_max     0.837692  \n",
       "r2_test_min     0.183978  \n",
       "r2_test_std     0.170011  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_results.T.to_csv('result/result_yield_s.csv', header=False)\n",
    "gen_results.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003f2fe5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
