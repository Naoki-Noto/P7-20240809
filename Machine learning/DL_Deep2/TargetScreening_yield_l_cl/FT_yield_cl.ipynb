{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69652f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\noton\\miniconda3\\envs\\Deep2\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipped loading modules with pytorch-geometric dependency, missing a dependency. No module named 'dgl'\n",
      "Skipped loading modules with transformers dependency. No module named 'transformers'\n",
      "cannot import name 'HuggingFaceModel' from 'deepchem.models.torch_models' (C:\\Users\\noton\\miniconda3\\envs\\Deep2\\lib\\site-packages\\deepchem\\models\\torch_models\\__init__.py)\n",
      "Skipped loading some Jax models, missing a dependency. No module named 'jax'\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import tensorflow as tf\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import deepchem as dc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, global_max_pool\n",
    "from torch_geometric.data import Batch, Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66bffaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GCNConv(30, 256)\n",
    "        self.conv2 = GCNConv(256, 256)\n",
    "        self.conv3 = GCNConv(256, 256)\n",
    "        self.conv4 = GCNConv(256, 256)\n",
    "        self.fc1 = nn.Linear(256, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 1)\n",
    "        self.dropout1 = nn.Dropout(p=0.35)\n",
    "        self.dropout2 = nn.Dropout(p=0.2)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv4(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = global_max_pool(x, data.batch)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "245051e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate(batch):\n",
    "    data_list, target_list = zip(*batch)\n",
    "    batch_data = Batch.from_data_list(data_list)\n",
    "    batch_target = torch.stack(target_list)\n",
    "    return batch_data, batch_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be45c11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_statistics(group):\n",
    "    r2_test = group['r2_test']\n",
    "    r2_test_dict = {f'run{i}': r2_test_val for i, r2_test_val in enumerate(r2_test)}\n",
    "    return pd.Series({\n",
    "        **r2_test_dict, \n",
    "        'r2_test_mean': np.mean(r2_test),\n",
    "        'r2_test_max': np.max(r2_test),\n",
    "        'r2_test_min': np.min(r2_test),\n",
    "        'r2_test_std': np.std(r2_test, ddof=0),\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53851fc9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "first_epochs = 50\n",
    "second_epochs = 200\n",
    "second_lr = 3e-3\n",
    "second_wd = 3e-6\n",
    "\n",
    "results = []\n",
    "for random_state in range(10):\n",
    "    torch.manual_seed(0)\n",
    "    \n",
    "    for dataset in [\"abcgg\", \"aatsc3d\", \"atsc3d\", \"kappa2\", \"peoevsa6\", \"bertzct\", \"ggi10\", \"vsaestate3\",\n",
    "                    \"atsc4i\", \"bcutp1l\", \"kappa3\", \"estatevsa3\", \"kier3\", \"aats8p\", \"kier2\", \"frnh0\"]:\n",
    "        torch.manual_seed(0)\n",
    "        \n",
    "        for t in [\"Yield_CO_cl\"]:\n",
    "            torch.manual_seed(0)\n",
    "            df = pd.read_csv('data_Real/data_real.csv')\n",
    "            smiles = df[\"SMILES\"]\n",
    "            featurizer = dc.feat.MolGraphConvFeaturizer(use_edges=True)\n",
    "            X = featurizer.featurize(smiles)\n",
    "            \n",
    "            y = df[t]\n",
    "            data_train, data_test, target_train, target_test = train_test_split(X, y, test_size=0.5, random_state=random_state)\n",
    "\n",
    "            target_train = scaler.fit_transform(target_train.values.reshape(-1, 1)).flatten()\n",
    "            target_test = scaler.transform(target_test.values.reshape(-1, 1)).flatten()\n",
    "            \n",
    "            target_train = torch.tensor(target_train, dtype=torch.float32)\n",
    "            target_test = torch.tensor(target_test, dtype=torch.float32)\n",
    "\n",
    "            data_train_list = []\n",
    "            for graph_data in data_train:\n",
    "                node_features = torch.tensor(graph_data.node_features, dtype=torch.float32)\n",
    "                edge_index = torch.tensor(graph_data.edge_index, dtype=torch.long)\n",
    "                edge_features = torch.tensor(graph_data.edge_features, dtype=torch.float32)\n",
    "                data = Data(x=node_features, edge_index=edge_index, edge_attr=edge_features)\n",
    "                data_train_list.append(data)\n",
    "\n",
    "            data_test_list = []\n",
    "            for graph_data in data_test:\n",
    "                node_features = torch.tensor(graph_data.node_features, dtype=torch.float32)\n",
    "                edge_index = torch.tensor(graph_data.edge_index, dtype=torch.long)\n",
    "                edge_features = torch.tensor(graph_data.edge_features, dtype=torch.float32)\n",
    "                data = Data(x=node_features, edge_index=edge_index, edge_attr=edge_features)\n",
    "                data_test_list.append(data)\n",
    "\n",
    "            train_loader = DataLoader(list(zip(data_train_list, target_train)), batch_size=len(data_train_list), collate_fn=custom_collate)\n",
    "            test_loader = DataLoader(list(zip(data_test_list, target_test)), batch_size=len(data_test_list), collate_fn=custom_collate)\n",
    "\n",
    "            model = Net()\n",
    "            model.load_state_dict(torch.load(f'data_AI+Human/model_{dataset}_sc.pth'))\n",
    "            model.fc3 = nn.Linear(128, 1)\n",
    "        \n",
    "            for param in model.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "            model.train()\n",
    "            optimizer = torch.optim.Adam(model.parameters())\n",
    "            criterion = nn.MSELoss()\n",
    "            \n",
    "            device = torch.device('cpu')\n",
    "            model.to(device)\n",
    "\n",
    "            for epoch in range(first_epochs):\n",
    "                for data, target in train_loader:\n",
    "                    data = data.to(device)\n",
    "                    target = target.to(device)\n",
    "                    with torch.no_grad():\n",
    "                        out = model(data)\n",
    "                        loss = criterion(out, target.view(-1, 1))\n",
    "\n",
    "            for param in model.fc1.parameters():\n",
    "                param.requires_grad = True\n",
    "            for param in model.fc2.parameters():\n",
    "                param.requires_grad = True\n",
    "            for param in model.fc3.parameters():\n",
    "                param.requires_grad = True\n",
    "\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=second_lr, weight_decay=second_wd)\n",
    "\n",
    "            for epoch in range(second_epochs):\n",
    "                for data, target in train_loader:\n",
    "                    data = data.to(device)\n",
    "                    target = target.to(device)\n",
    "                    optimizer.zero_grad()\n",
    "                    out = model(data)\n",
    "                    loss = criterion(out, target.view(-1, 1))\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            model.eval()\n",
    "            pred_train = []\n",
    "            for data, target in train_loader:\n",
    "                data = data.to(device)\n",
    "                with torch.no_grad():\n",
    "                    out = model(data)\n",
    "                pred_train.append(out.cpu().numpy())\n",
    "            pred_train = np.concatenate(pred_train)\n",
    "\n",
    "            pred_test = []\n",
    "            for data, target in test_loader:\n",
    "                data = data.to(device)\n",
    "                with torch.no_grad():\n",
    "                    out = model(data)\n",
    "                pred_test.append(out.cpu().numpy())\n",
    "            pred_test = np.concatenate(pred_test)\n",
    "\n",
    "            pred_train = scaler.inverse_transform(pred_train)\n",
    "            pred_test = scaler.inverse_transform(pred_test)\n",
    "            target_train = scaler.inverse_transform(target_train.numpy().reshape(-1, 1)).flatten()\n",
    "            target_test = scaler.inverse_transform(target_test.numpy().reshape(-1, 1)).flatten()\n",
    "\n",
    "            r2_test_score = metrics.r2_score(target_test, pred_test)\n",
    "            results.append({'source': dataset, 'target': t, 'r2_test': r2_test_score})\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "gen_results = results_df.groupby(['source', 'target']).apply(calculate_statistics).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "463235ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>source</th>\n",
       "      <td>aats8p</td>\n",
       "      <td>aatsc3d</td>\n",
       "      <td>abcgg</td>\n",
       "      <td>atsc3d</td>\n",
       "      <td>atsc4i</td>\n",
       "      <td>bcutp1l</td>\n",
       "      <td>bertzct</td>\n",
       "      <td>estatevsa3</td>\n",
       "      <td>frnh0</td>\n",
       "      <td>ggi10</td>\n",
       "      <td>kappa2</td>\n",
       "      <td>kappa3</td>\n",
       "      <td>kier2</td>\n",
       "      <td>kier3</td>\n",
       "      <td>peoevsa6</td>\n",
       "      <td>vsaestate3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>Yield_CO_cl</td>\n",
       "      <td>Yield_CO_cl</td>\n",
       "      <td>Yield_CO_cl</td>\n",
       "      <td>Yield_CO_cl</td>\n",
       "      <td>Yield_CO_cl</td>\n",
       "      <td>Yield_CO_cl</td>\n",
       "      <td>Yield_CO_cl</td>\n",
       "      <td>Yield_CO_cl</td>\n",
       "      <td>Yield_CO_cl</td>\n",
       "      <td>Yield_CO_cl</td>\n",
       "      <td>Yield_CO_cl</td>\n",
       "      <td>Yield_CO_cl</td>\n",
       "      <td>Yield_CO_cl</td>\n",
       "      <td>Yield_CO_cl</td>\n",
       "      <td>Yield_CO_cl</td>\n",
       "      <td>Yield_CO_cl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run0</th>\n",
       "      <td>0.598764</td>\n",
       "      <td>0.596139</td>\n",
       "      <td>0.652558</td>\n",
       "      <td>0.520131</td>\n",
       "      <td>0.28759</td>\n",
       "      <td>0.58195</td>\n",
       "      <td>0.706739</td>\n",
       "      <td>0.461257</td>\n",
       "      <td>0.656188</td>\n",
       "      <td>0.653203</td>\n",
       "      <td>0.755419</td>\n",
       "      <td>0.805324</td>\n",
       "      <td>0.700898</td>\n",
       "      <td>0.555853</td>\n",
       "      <td>0.761473</td>\n",
       "      <td>0.692211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run1</th>\n",
       "      <td>0.610108</td>\n",
       "      <td>0.662182</td>\n",
       "      <td>0.716233</td>\n",
       "      <td>0.519694</td>\n",
       "      <td>0.557298</td>\n",
       "      <td>0.3003</td>\n",
       "      <td>0.783068</td>\n",
       "      <td>0.548715</td>\n",
       "      <td>0.644774</td>\n",
       "      <td>0.675429</td>\n",
       "      <td>0.738465</td>\n",
       "      <td>0.736885</td>\n",
       "      <td>0.768763</td>\n",
       "      <td>0.627356</td>\n",
       "      <td>0.537437</td>\n",
       "      <td>0.500584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run2</th>\n",
       "      <td>0.472819</td>\n",
       "      <td>0.723959</td>\n",
       "      <td>0.65985</td>\n",
       "      <td>0.573464</td>\n",
       "      <td>0.348862</td>\n",
       "      <td>0.499815</td>\n",
       "      <td>0.709869</td>\n",
       "      <td>0.46194</td>\n",
       "      <td>0.706808</td>\n",
       "      <td>0.626562</td>\n",
       "      <td>0.843841</td>\n",
       "      <td>0.760291</td>\n",
       "      <td>0.714713</td>\n",
       "      <td>0.519459</td>\n",
       "      <td>0.697392</td>\n",
       "      <td>0.673133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run3</th>\n",
       "      <td>0.746739</td>\n",
       "      <td>0.708372</td>\n",
       "      <td>0.764195</td>\n",
       "      <td>0.762791</td>\n",
       "      <td>0.749774</td>\n",
       "      <td>0.319146</td>\n",
       "      <td>0.818508</td>\n",
       "      <td>0.672297</td>\n",
       "      <td>0.671985</td>\n",
       "      <td>0.709822</td>\n",
       "      <td>0.825378</td>\n",
       "      <td>0.77819</td>\n",
       "      <td>0.794197</td>\n",
       "      <td>0.770815</td>\n",
       "      <td>0.682928</td>\n",
       "      <td>0.65233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run4</th>\n",
       "      <td>0.771418</td>\n",
       "      <td>0.749537</td>\n",
       "      <td>0.785924</td>\n",
       "      <td>0.740709</td>\n",
       "      <td>0.785414</td>\n",
       "      <td>0.628613</td>\n",
       "      <td>0.838503</td>\n",
       "      <td>0.70679</td>\n",
       "      <td>0.776589</td>\n",
       "      <td>0.765632</td>\n",
       "      <td>0.811128</td>\n",
       "      <td>0.801839</td>\n",
       "      <td>0.776822</td>\n",
       "      <td>0.755317</td>\n",
       "      <td>0.733042</td>\n",
       "      <td>0.673353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run5</th>\n",
       "      <td>0.649495</td>\n",
       "      <td>0.599401</td>\n",
       "      <td>0.70631</td>\n",
       "      <td>0.618548</td>\n",
       "      <td>0.628249</td>\n",
       "      <td>0.595204</td>\n",
       "      <td>0.776741</td>\n",
       "      <td>0.678742</td>\n",
       "      <td>0.741042</td>\n",
       "      <td>0.699763</td>\n",
       "      <td>0.779025</td>\n",
       "      <td>0.716127</td>\n",
       "      <td>0.695596</td>\n",
       "      <td>0.678089</td>\n",
       "      <td>0.712029</td>\n",
       "      <td>0.694081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run6</th>\n",
       "      <td>0.727392</td>\n",
       "      <td>0.729596</td>\n",
       "      <td>0.786928</td>\n",
       "      <td>0.755668</td>\n",
       "      <td>0.641706</td>\n",
       "      <td>0.422302</td>\n",
       "      <td>0.769796</td>\n",
       "      <td>0.741615</td>\n",
       "      <td>0.756203</td>\n",
       "      <td>0.715835</td>\n",
       "      <td>0.790685</td>\n",
       "      <td>0.777706</td>\n",
       "      <td>0.774704</td>\n",
       "      <td>0.6535</td>\n",
       "      <td>0.613348</td>\n",
       "      <td>0.720446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run7</th>\n",
       "      <td>0.682579</td>\n",
       "      <td>0.662192</td>\n",
       "      <td>0.730352</td>\n",
       "      <td>0.714684</td>\n",
       "      <td>0.715812</td>\n",
       "      <td>0.526824</td>\n",
       "      <td>0.74033</td>\n",
       "      <td>0.644772</td>\n",
       "      <td>0.697458</td>\n",
       "      <td>0.728053</td>\n",
       "      <td>0.791869</td>\n",
       "      <td>0.71345</td>\n",
       "      <td>0.756946</td>\n",
       "      <td>0.737799</td>\n",
       "      <td>0.695776</td>\n",
       "      <td>0.707092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run8</th>\n",
       "      <td>0.605912</td>\n",
       "      <td>0.537397</td>\n",
       "      <td>0.496909</td>\n",
       "      <td>0.599756</td>\n",
       "      <td>0.547525</td>\n",
       "      <td>-0.074918</td>\n",
       "      <td>0.641667</td>\n",
       "      <td>0.548585</td>\n",
       "      <td>0.625975</td>\n",
       "      <td>0.521362</td>\n",
       "      <td>0.680876</td>\n",
       "      <td>0.659557</td>\n",
       "      <td>0.641232</td>\n",
       "      <td>0.583336</td>\n",
       "      <td>0.635526</td>\n",
       "      <td>0.465513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run9</th>\n",
       "      <td>0.588612</td>\n",
       "      <td>0.560799</td>\n",
       "      <td>0.701009</td>\n",
       "      <td>0.59326</td>\n",
       "      <td>0.604514</td>\n",
       "      <td>0.402278</td>\n",
       "      <td>0.695515</td>\n",
       "      <td>0.618672</td>\n",
       "      <td>0.585558</td>\n",
       "      <td>0.578898</td>\n",
       "      <td>0.706636</td>\n",
       "      <td>0.657075</td>\n",
       "      <td>0.705533</td>\n",
       "      <td>0.590673</td>\n",
       "      <td>0.586991</td>\n",
       "      <td>0.652817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2_test_mean</th>\n",
       "      <td>0.645384</td>\n",
       "      <td>0.652957</td>\n",
       "      <td>0.700027</td>\n",
       "      <td>0.63987</td>\n",
       "      <td>0.586674</td>\n",
       "      <td>0.420151</td>\n",
       "      <td>0.748074</td>\n",
       "      <td>0.608339</td>\n",
       "      <td>0.686258</td>\n",
       "      <td>0.667456</td>\n",
       "      <td>0.772332</td>\n",
       "      <td>0.740644</td>\n",
       "      <td>0.73294</td>\n",
       "      <td>0.64722</td>\n",
       "      <td>0.665594</td>\n",
       "      <td>0.643156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2_test_max</th>\n",
       "      <td>0.771418</td>\n",
       "      <td>0.749537</td>\n",
       "      <td>0.786928</td>\n",
       "      <td>0.762791</td>\n",
       "      <td>0.785414</td>\n",
       "      <td>0.628613</td>\n",
       "      <td>0.838503</td>\n",
       "      <td>0.741615</td>\n",
       "      <td>0.776589</td>\n",
       "      <td>0.765632</td>\n",
       "      <td>0.843841</td>\n",
       "      <td>0.805324</td>\n",
       "      <td>0.794197</td>\n",
       "      <td>0.770815</td>\n",
       "      <td>0.761473</td>\n",
       "      <td>0.720446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2_test_min</th>\n",
       "      <td>0.472819</td>\n",
       "      <td>0.537397</td>\n",
       "      <td>0.496909</td>\n",
       "      <td>0.519694</td>\n",
       "      <td>0.28759</td>\n",
       "      <td>-0.074918</td>\n",
       "      <td>0.641667</td>\n",
       "      <td>0.461257</td>\n",
       "      <td>0.585558</td>\n",
       "      <td>0.521362</td>\n",
       "      <td>0.680876</td>\n",
       "      <td>0.657075</td>\n",
       "      <td>0.641232</td>\n",
       "      <td>0.519459</td>\n",
       "      <td>0.537437</td>\n",
       "      <td>0.465513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2_test_std</th>\n",
       "      <td>0.085006</td>\n",
       "      <td>0.071713</td>\n",
       "      <td>0.080867</td>\n",
       "      <td>0.090394</td>\n",
       "      <td>0.153705</td>\n",
       "      <td>0.196974</td>\n",
       "      <td>0.057419</td>\n",
       "      <td>0.093876</td>\n",
       "      <td>0.057623</td>\n",
       "      <td>0.070438</td>\n",
       "      <td>0.049304</td>\n",
       "      <td>0.051001</td>\n",
       "      <td>0.04604</td>\n",
       "      <td>0.082766</td>\n",
       "      <td>0.066601</td>\n",
       "      <td>0.083026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0            1            2            3            4   \\\n",
       "source             aats8p      aatsc3d        abcgg       atsc3d       atsc4i   \n",
       "target        Yield_CO_cl  Yield_CO_cl  Yield_CO_cl  Yield_CO_cl  Yield_CO_cl   \n",
       "run0             0.598764     0.596139     0.652558     0.520131      0.28759   \n",
       "run1             0.610108     0.662182     0.716233     0.519694     0.557298   \n",
       "run2             0.472819     0.723959      0.65985     0.573464     0.348862   \n",
       "run3             0.746739     0.708372     0.764195     0.762791     0.749774   \n",
       "run4             0.771418     0.749537     0.785924     0.740709     0.785414   \n",
       "run5             0.649495     0.599401      0.70631     0.618548     0.628249   \n",
       "run6             0.727392     0.729596     0.786928     0.755668     0.641706   \n",
       "run7             0.682579     0.662192     0.730352     0.714684     0.715812   \n",
       "run8             0.605912     0.537397     0.496909     0.599756     0.547525   \n",
       "run9             0.588612     0.560799     0.701009      0.59326     0.604514   \n",
       "r2_test_mean     0.645384     0.652957     0.700027      0.63987     0.586674   \n",
       "r2_test_max      0.771418     0.749537     0.786928     0.762791     0.785414   \n",
       "r2_test_min      0.472819     0.537397     0.496909     0.519694      0.28759   \n",
       "r2_test_std      0.085006     0.071713     0.080867     0.090394     0.153705   \n",
       "\n",
       "                       5            6            7            8            9   \\\n",
       "source            bcutp1l      bertzct   estatevsa3        frnh0        ggi10   \n",
       "target        Yield_CO_cl  Yield_CO_cl  Yield_CO_cl  Yield_CO_cl  Yield_CO_cl   \n",
       "run0              0.58195     0.706739     0.461257     0.656188     0.653203   \n",
       "run1               0.3003     0.783068     0.548715     0.644774     0.675429   \n",
       "run2             0.499815     0.709869      0.46194     0.706808     0.626562   \n",
       "run3             0.319146     0.818508     0.672297     0.671985     0.709822   \n",
       "run4             0.628613     0.838503      0.70679     0.776589     0.765632   \n",
       "run5             0.595204     0.776741     0.678742     0.741042     0.699763   \n",
       "run6             0.422302     0.769796     0.741615     0.756203     0.715835   \n",
       "run7             0.526824      0.74033     0.644772     0.697458     0.728053   \n",
       "run8            -0.074918     0.641667     0.548585     0.625975     0.521362   \n",
       "run9             0.402278     0.695515     0.618672     0.585558     0.578898   \n",
       "r2_test_mean     0.420151     0.748074     0.608339     0.686258     0.667456   \n",
       "r2_test_max      0.628613     0.838503     0.741615     0.776589     0.765632   \n",
       "r2_test_min     -0.074918     0.641667     0.461257     0.585558     0.521362   \n",
       "r2_test_std      0.196974     0.057419     0.093876     0.057623     0.070438   \n",
       "\n",
       "                       10           11           12           13           14  \\\n",
       "source             kappa2       kappa3        kier2        kier3     peoevsa6   \n",
       "target        Yield_CO_cl  Yield_CO_cl  Yield_CO_cl  Yield_CO_cl  Yield_CO_cl   \n",
       "run0             0.755419     0.805324     0.700898     0.555853     0.761473   \n",
       "run1             0.738465     0.736885     0.768763     0.627356     0.537437   \n",
       "run2             0.843841     0.760291     0.714713     0.519459     0.697392   \n",
       "run3             0.825378      0.77819     0.794197     0.770815     0.682928   \n",
       "run4             0.811128     0.801839     0.776822     0.755317     0.733042   \n",
       "run5             0.779025     0.716127     0.695596     0.678089     0.712029   \n",
       "run6             0.790685     0.777706     0.774704       0.6535     0.613348   \n",
       "run7             0.791869      0.71345     0.756946     0.737799     0.695776   \n",
       "run8             0.680876     0.659557     0.641232     0.583336     0.635526   \n",
       "run9             0.706636     0.657075     0.705533     0.590673     0.586991   \n",
       "r2_test_mean     0.772332     0.740644      0.73294      0.64722     0.665594   \n",
       "r2_test_max      0.843841     0.805324     0.794197     0.770815     0.761473   \n",
       "r2_test_min      0.680876     0.657075     0.641232     0.519459     0.537437   \n",
       "r2_test_std      0.049304     0.051001      0.04604     0.082766     0.066601   \n",
       "\n",
       "                       15  \n",
       "source         vsaestate3  \n",
       "target        Yield_CO_cl  \n",
       "run0             0.692211  \n",
       "run1             0.500584  \n",
       "run2             0.673133  \n",
       "run3              0.65233  \n",
       "run4             0.673353  \n",
       "run5             0.694081  \n",
       "run6             0.720446  \n",
       "run7             0.707092  \n",
       "run8             0.465513  \n",
       "run9             0.652817  \n",
       "r2_test_mean     0.643156  \n",
       "r2_test_max      0.720446  \n",
       "r2_test_min      0.465513  \n",
       "r2_test_std      0.083026  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_results.T.to_csv('result/result_yield_cl.csv', header=False)\n",
    "gen_results.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003f2fe5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
