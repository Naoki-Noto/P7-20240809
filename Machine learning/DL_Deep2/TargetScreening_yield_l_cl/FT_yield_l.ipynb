{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69652f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\noton\\miniconda3\\envs\\Deep2\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipped loading modules with pytorch-geometric dependency, missing a dependency. No module named 'dgl'\n",
      "Skipped loading modules with transformers dependency. No module named 'transformers'\n",
      "cannot import name 'HuggingFaceModel' from 'deepchem.models.torch_models' (C:\\Users\\noton\\miniconda3\\envs\\Deep2\\lib\\site-packages\\deepchem\\models\\torch_models\\__init__.py)\n",
      "Skipped loading some Jax models, missing a dependency. No module named 'jax'\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import tensorflow as tf\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import deepchem as dc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, global_max_pool\n",
    "from torch_geometric.data import Batch, Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66bffaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GCNConv(30, 256)\n",
    "        self.conv2 = GCNConv(256, 256)\n",
    "        self.conv3 = GCNConv(256, 256)\n",
    "        self.conv4 = GCNConv(256, 256)\n",
    "        self.fc1 = nn.Linear(256, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 1)\n",
    "        self.dropout1 = nn.Dropout(p=0.2)\n",
    "        self.dropout2 = nn.Dropout(p=0.2)\n",
    "        self.dropout3 = nn.Dropout(p=0.2)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv4(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = global_max_pool(x, data.batch)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "245051e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate(batch):\n",
    "    data_list, target_list = zip(*batch)\n",
    "    batch_data = Batch.from_data_list(data_list)\n",
    "    batch_target = torch.stack(target_list)\n",
    "    return batch_data, batch_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be45c11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_statistics(group):\n",
    "    r2_test = group['r2_test']\n",
    "    r2_test_dict = {f'run{i}': r2_test_val for i, r2_test_val in enumerate(r2_test)}\n",
    "    return pd.Series({\n",
    "        **r2_test_dict, \n",
    "        'r2_test_mean': np.mean(r2_test),\n",
    "        'r2_test_max': np.max(r2_test),\n",
    "        'r2_test_min': np.min(r2_test),\n",
    "        'r2_test_std': np.std(r2_test, ddof=0),\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53851fc9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "first_epochs = 50\n",
    "second_epochs = 200\n",
    "second_lr = 9e-3\n",
    "second_wd = 3e-5\n",
    "\n",
    "results = []\n",
    "for random_state in range(10):\n",
    "    torch.manual_seed(0)\n",
    "    \n",
    "    for dataset in [\"abcgg\", \"aatsc3d\", \"atsc3d\", \"kappa2\", \"peoevsa6\", \"bertzct\", \"ggi10\", \"vsaestate3\",\n",
    "                    \"atsc4i\", \"bcutp1l\", \"kappa3\", \"estatevsa3\", \"kier3\", \"aats8p\", \"kier2\", \"frnh0\"]:\n",
    "        torch.manual_seed(0)\n",
    "        \n",
    "        for d in [\"Yield_CO_l\"]:\n",
    "            torch.manual_seed(0)\n",
    "            df = pd.read_csv('data_Real/data_real.csv')\n",
    "            smiles = df[\"SMILES\"]\n",
    "            featurizer = dc.feat.MolGraphConvFeaturizer(use_edges=True)\n",
    "            X = featurizer.featurize(smiles)\n",
    "            \n",
    "            y = df[d]\n",
    "            data_train, data_test, target_train, target_test = train_test_split(X, y, test_size=0.5, random_state=random_state)\n",
    "\n",
    "            target_train = scaler.fit_transform(target_train.values.reshape(-1, 1)).flatten()\n",
    "            target_test = scaler.transform(target_test.values.reshape(-1, 1)).flatten()\n",
    "            \n",
    "            target_train = torch.tensor(target_train, dtype=torch.float32)\n",
    "            target_test = torch.tensor(target_test, dtype=torch.float32)\n",
    "\n",
    "            data_train_list = []\n",
    "            for graph_data in data_train:\n",
    "                node_features = torch.tensor(graph_data.node_features, dtype=torch.float32)\n",
    "                edge_index = torch.tensor(graph_data.edge_index, dtype=torch.long)\n",
    "                edge_features = torch.tensor(graph_data.edge_features, dtype=torch.float32)\n",
    "                data = Data(x=node_features, edge_index=edge_index, edge_attr=edge_features)\n",
    "                data_train_list.append(data)\n",
    "\n",
    "            data_test_list = []\n",
    "            for graph_data in data_test:\n",
    "                node_features = torch.tensor(graph_data.node_features, dtype=torch.float32)\n",
    "                edge_index = torch.tensor(graph_data.edge_index, dtype=torch.long)\n",
    "                edge_features = torch.tensor(graph_data.edge_features, dtype=torch.float32)\n",
    "                data = Data(x=node_features, edge_index=edge_index, edge_attr=edge_features)\n",
    "                data_test_list.append(data)\n",
    "\n",
    "            train_loader = DataLoader(list(zip(data_train_list, target_train)), batch_size=len(data_train_list), collate_fn=custom_collate)\n",
    "            test_loader = DataLoader(list(zip(data_test_list, target_test)), batch_size=len(data_test_list), collate_fn=custom_collate)\n",
    "\n",
    "            model = Net()\n",
    "            model.load_state_dict(torch.load(f'data_AI+Human/model_{dataset}_sc.pth'))\n",
    "            model.fc3 = nn.Linear(128, 1)\n",
    "        \n",
    "            for param in model.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "            model.train()\n",
    "            optimizer = torch.optim.Adam(model.parameters())\n",
    "            criterion = nn.MSELoss()\n",
    "            \n",
    "            device = torch.device('cpu')\n",
    "            model.to(device)\n",
    "\n",
    "            for epoch in range(first_epochs):\n",
    "                for data, target in train_loader:\n",
    "                    data = data.to(device)\n",
    "                    target = target.to(device)\n",
    "                    with torch.no_grad():\n",
    "                        out = model(data)\n",
    "                        loss = criterion(out, target.view(-1, 1))\n",
    "\n",
    "            for param in model.fc1.parameters():\n",
    "                param.requires_grad = True\n",
    "            for param in model.fc2.parameters():\n",
    "                param.requires_grad = True\n",
    "            for param in model.fc3.parameters():\n",
    "                param.requires_grad = True\n",
    "\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=second_lr, weight_decay=second_wd)\n",
    "\n",
    "            for epoch in range(second_epochs):\n",
    "                for data, target in train_loader:\n",
    "                    data = data.to(device)\n",
    "                    target = target.to(device)\n",
    "                    optimizer.zero_grad()\n",
    "                    out = model(data)\n",
    "                    loss = criterion(out, target.view(-1, 1))\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            model.eval()\n",
    "            pred_train = []\n",
    "            for data, target in train_loader:\n",
    "                data = data.to(device)\n",
    "                with torch.no_grad():\n",
    "                    out = model(data)\n",
    "                pred_train.append(out.cpu().numpy())\n",
    "            pred_train = np.concatenate(pred_train)\n",
    "\n",
    "            pred_test = []\n",
    "            for data, target in test_loader:\n",
    "                data = data.to(device)\n",
    "                with torch.no_grad():\n",
    "                    out = model(data)\n",
    "                pred_test.append(out.cpu().numpy())\n",
    "            pred_test = np.concatenate(pred_test)\n",
    "\n",
    "            pred_train = scaler.inverse_transform(pred_train)\n",
    "            pred_test = scaler.inverse_transform(pred_test)\n",
    "            target_train = scaler.inverse_transform(target_train.numpy().reshape(-1, 1)).flatten()\n",
    "            target_test = scaler.inverse_transform(target_test.numpy().reshape(-1, 1)).flatten()\n",
    "\n",
    "            r2_test_score = metrics.r2_score(target_test, pred_test)\n",
    "            results.append({'source': dataset, 'target': d, 'r2_test': r2_test_score})\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "gen_results = results_df.groupby(['source', 'target']).apply(calculate_statistics).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "463235ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>source</th>\n",
       "      <td>aats8p</td>\n",
       "      <td>aatsc3d</td>\n",
       "      <td>abcgg</td>\n",
       "      <td>atsc3d</td>\n",
       "      <td>atsc4i</td>\n",
       "      <td>bcutp1l</td>\n",
       "      <td>bertzct</td>\n",
       "      <td>estatevsa3</td>\n",
       "      <td>frnh0</td>\n",
       "      <td>ggi10</td>\n",
       "      <td>kappa2</td>\n",
       "      <td>kappa3</td>\n",
       "      <td>kier2</td>\n",
       "      <td>kier3</td>\n",
       "      <td>peoevsa6</td>\n",
       "      <td>vsaestate3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>Yield_CO_l</td>\n",
       "      <td>Yield_CO_l</td>\n",
       "      <td>Yield_CO_l</td>\n",
       "      <td>Yield_CO_l</td>\n",
       "      <td>Yield_CO_l</td>\n",
       "      <td>Yield_CO_l</td>\n",
       "      <td>Yield_CO_l</td>\n",
       "      <td>Yield_CO_l</td>\n",
       "      <td>Yield_CO_l</td>\n",
       "      <td>Yield_CO_l</td>\n",
       "      <td>Yield_CO_l</td>\n",
       "      <td>Yield_CO_l</td>\n",
       "      <td>Yield_CO_l</td>\n",
       "      <td>Yield_CO_l</td>\n",
       "      <td>Yield_CO_l</td>\n",
       "      <td>Yield_CO_l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run0</th>\n",
       "      <td>0.649392</td>\n",
       "      <td>0.61097</td>\n",
       "      <td>0.645439</td>\n",
       "      <td>0.513372</td>\n",
       "      <td>0.592144</td>\n",
       "      <td>0.269883</td>\n",
       "      <td>0.812801</td>\n",
       "      <td>0.551847</td>\n",
       "      <td>0.782722</td>\n",
       "      <td>0.656078</td>\n",
       "      <td>0.743976</td>\n",
       "      <td>0.77899</td>\n",
       "      <td>0.771879</td>\n",
       "      <td>0.623508</td>\n",
       "      <td>0.74919</td>\n",
       "      <td>0.750224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run1</th>\n",
       "      <td>0.637718</td>\n",
       "      <td>0.582033</td>\n",
       "      <td>0.632658</td>\n",
       "      <td>0.492685</td>\n",
       "      <td>0.5191</td>\n",
       "      <td>0.38466</td>\n",
       "      <td>0.730531</td>\n",
       "      <td>0.567091</td>\n",
       "      <td>0.621344</td>\n",
       "      <td>0.627303</td>\n",
       "      <td>0.706477</td>\n",
       "      <td>0.709109</td>\n",
       "      <td>0.696214</td>\n",
       "      <td>0.612447</td>\n",
       "      <td>0.434815</td>\n",
       "      <td>0.540272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run2</th>\n",
       "      <td>0.673924</td>\n",
       "      <td>0.786879</td>\n",
       "      <td>0.752974</td>\n",
       "      <td>0.610729</td>\n",
       "      <td>0.626806</td>\n",
       "      <td>0.541209</td>\n",
       "      <td>0.86877</td>\n",
       "      <td>0.714396</td>\n",
       "      <td>0.761118</td>\n",
       "      <td>0.750833</td>\n",
       "      <td>0.867585</td>\n",
       "      <td>0.787675</td>\n",
       "      <td>0.812739</td>\n",
       "      <td>0.731423</td>\n",
       "      <td>0.779552</td>\n",
       "      <td>0.68947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run3</th>\n",
       "      <td>0.783766</td>\n",
       "      <td>0.757735</td>\n",
       "      <td>0.813356</td>\n",
       "      <td>0.829347</td>\n",
       "      <td>0.809863</td>\n",
       "      <td>0.393738</td>\n",
       "      <td>0.843678</td>\n",
       "      <td>0.72649</td>\n",
       "      <td>0.780898</td>\n",
       "      <td>0.767473</td>\n",
       "      <td>0.828764</td>\n",
       "      <td>0.798319</td>\n",
       "      <td>0.794394</td>\n",
       "      <td>0.769773</td>\n",
       "      <td>0.810217</td>\n",
       "      <td>0.626807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run4</th>\n",
       "      <td>0.834621</td>\n",
       "      <td>0.704318</td>\n",
       "      <td>0.787701</td>\n",
       "      <td>0.683662</td>\n",
       "      <td>0.777027</td>\n",
       "      <td>0.495636</td>\n",
       "      <td>0.805093</td>\n",
       "      <td>0.816411</td>\n",
       "      <td>0.79574</td>\n",
       "      <td>0.716682</td>\n",
       "      <td>0.682293</td>\n",
       "      <td>0.736768</td>\n",
       "      <td>0.810371</td>\n",
       "      <td>0.734656</td>\n",
       "      <td>0.729102</td>\n",
       "      <td>0.708957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run5</th>\n",
       "      <td>0.787557</td>\n",
       "      <td>0.670463</td>\n",
       "      <td>0.706456</td>\n",
       "      <td>0.677229</td>\n",
       "      <td>0.593005</td>\n",
       "      <td>0.412733</td>\n",
       "      <td>0.78845</td>\n",
       "      <td>0.778011</td>\n",
       "      <td>0.745597</td>\n",
       "      <td>0.688521</td>\n",
       "      <td>0.732981</td>\n",
       "      <td>0.634234</td>\n",
       "      <td>0.667826</td>\n",
       "      <td>0.666916</td>\n",
       "      <td>0.617242</td>\n",
       "      <td>0.765446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run6</th>\n",
       "      <td>0.747547</td>\n",
       "      <td>0.644217</td>\n",
       "      <td>0.660416</td>\n",
       "      <td>0.650437</td>\n",
       "      <td>0.589431</td>\n",
       "      <td>0.374955</td>\n",
       "      <td>0.759998</td>\n",
       "      <td>0.760721</td>\n",
       "      <td>0.737953</td>\n",
       "      <td>0.682937</td>\n",
       "      <td>0.813488</td>\n",
       "      <td>0.804161</td>\n",
       "      <td>0.783546</td>\n",
       "      <td>0.749075</td>\n",
       "      <td>0.786008</td>\n",
       "      <td>0.668113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run7</th>\n",
       "      <td>0.777936</td>\n",
       "      <td>0.716725</td>\n",
       "      <td>0.798196</td>\n",
       "      <td>0.741974</td>\n",
       "      <td>0.747941</td>\n",
       "      <td>0.449164</td>\n",
       "      <td>0.843004</td>\n",
       "      <td>0.691703</td>\n",
       "      <td>0.768386</td>\n",
       "      <td>0.775483</td>\n",
       "      <td>0.778147</td>\n",
       "      <td>0.791514</td>\n",
       "      <td>0.788254</td>\n",
       "      <td>0.779334</td>\n",
       "      <td>0.754569</td>\n",
       "      <td>0.733546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run8</th>\n",
       "      <td>0.783601</td>\n",
       "      <td>0.635415</td>\n",
       "      <td>0.65232</td>\n",
       "      <td>0.681988</td>\n",
       "      <td>0.658288</td>\n",
       "      <td>0.320518</td>\n",
       "      <td>0.760072</td>\n",
       "      <td>0.640365</td>\n",
       "      <td>0.714921</td>\n",
       "      <td>0.699422</td>\n",
       "      <td>0.75557</td>\n",
       "      <td>0.677369</td>\n",
       "      <td>0.759797</td>\n",
       "      <td>0.703394</td>\n",
       "      <td>0.70251</td>\n",
       "      <td>0.66079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run9</th>\n",
       "      <td>0.731611</td>\n",
       "      <td>0.61193</td>\n",
       "      <td>0.717897</td>\n",
       "      <td>0.655888</td>\n",
       "      <td>0.661294</td>\n",
       "      <td>0.529278</td>\n",
       "      <td>0.787077</td>\n",
       "      <td>0.629437</td>\n",
       "      <td>0.670808</td>\n",
       "      <td>0.724172</td>\n",
       "      <td>0.758061</td>\n",
       "      <td>0.722292</td>\n",
       "      <td>0.756144</td>\n",
       "      <td>0.714432</td>\n",
       "      <td>0.731896</td>\n",
       "      <td>0.623074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2_test_mean</th>\n",
       "      <td>0.740767</td>\n",
       "      <td>0.672069</td>\n",
       "      <td>0.716741</td>\n",
       "      <td>0.653731</td>\n",
       "      <td>0.65749</td>\n",
       "      <td>0.417177</td>\n",
       "      <td>0.799947</td>\n",
       "      <td>0.687647</td>\n",
       "      <td>0.737949</td>\n",
       "      <td>0.70889</td>\n",
       "      <td>0.766734</td>\n",
       "      <td>0.744043</td>\n",
       "      <td>0.764117</td>\n",
       "      <td>0.708496</td>\n",
       "      <td>0.70951</td>\n",
       "      <td>0.67667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2_test_max</th>\n",
       "      <td>0.834621</td>\n",
       "      <td>0.786879</td>\n",
       "      <td>0.813356</td>\n",
       "      <td>0.829347</td>\n",
       "      <td>0.809863</td>\n",
       "      <td>0.541209</td>\n",
       "      <td>0.86877</td>\n",
       "      <td>0.816411</td>\n",
       "      <td>0.79574</td>\n",
       "      <td>0.775483</td>\n",
       "      <td>0.867585</td>\n",
       "      <td>0.804161</td>\n",
       "      <td>0.812739</td>\n",
       "      <td>0.779334</td>\n",
       "      <td>0.810217</td>\n",
       "      <td>0.765446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2_test_min</th>\n",
       "      <td>0.637718</td>\n",
       "      <td>0.582033</td>\n",
       "      <td>0.632658</td>\n",
       "      <td>0.492685</td>\n",
       "      <td>0.5191</td>\n",
       "      <td>0.269883</td>\n",
       "      <td>0.730531</td>\n",
       "      <td>0.551847</td>\n",
       "      <td>0.621344</td>\n",
       "      <td>0.627303</td>\n",
       "      <td>0.682293</td>\n",
       "      <td>0.634234</td>\n",
       "      <td>0.667826</td>\n",
       "      <td>0.612447</td>\n",
       "      <td>0.434815</td>\n",
       "      <td>0.540272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2_test_std</th>\n",
       "      <td>0.062952</td>\n",
       "      <td>0.064134</td>\n",
       "      <td>0.064731</td>\n",
       "      <td>0.094008</td>\n",
       "      <td>0.088801</td>\n",
       "      <td>0.083413</td>\n",
       "      <td>0.041227</td>\n",
       "      <td>0.084217</td>\n",
       "      <td>0.052293</td>\n",
       "      <td>0.045325</td>\n",
       "      <td>0.053808</td>\n",
       "      <td>0.054944</td>\n",
       "      <td>0.045173</td>\n",
       "      <td>0.054652</td>\n",
       "      <td>0.104599</td>\n",
       "      <td>0.064824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0           1           2           3           4   \\\n",
       "source            aats8p     aatsc3d       abcgg      atsc3d      atsc4i   \n",
       "target        Yield_CO_l  Yield_CO_l  Yield_CO_l  Yield_CO_l  Yield_CO_l   \n",
       "run0            0.649392     0.61097    0.645439    0.513372    0.592144   \n",
       "run1            0.637718    0.582033    0.632658    0.492685      0.5191   \n",
       "run2            0.673924    0.786879    0.752974    0.610729    0.626806   \n",
       "run3            0.783766    0.757735    0.813356    0.829347    0.809863   \n",
       "run4            0.834621    0.704318    0.787701    0.683662    0.777027   \n",
       "run5            0.787557    0.670463    0.706456    0.677229    0.593005   \n",
       "run6            0.747547    0.644217    0.660416    0.650437    0.589431   \n",
       "run7            0.777936    0.716725    0.798196    0.741974    0.747941   \n",
       "run8            0.783601    0.635415     0.65232    0.681988    0.658288   \n",
       "run9            0.731611     0.61193    0.717897    0.655888    0.661294   \n",
       "r2_test_mean    0.740767    0.672069    0.716741    0.653731     0.65749   \n",
       "r2_test_max     0.834621    0.786879    0.813356    0.829347    0.809863   \n",
       "r2_test_min     0.637718    0.582033    0.632658    0.492685      0.5191   \n",
       "r2_test_std     0.062952    0.064134    0.064731    0.094008    0.088801   \n",
       "\n",
       "                      5           6           7           8           9   \\\n",
       "source           bcutp1l     bertzct  estatevsa3       frnh0       ggi10   \n",
       "target        Yield_CO_l  Yield_CO_l  Yield_CO_l  Yield_CO_l  Yield_CO_l   \n",
       "run0            0.269883    0.812801    0.551847    0.782722    0.656078   \n",
       "run1             0.38466    0.730531    0.567091    0.621344    0.627303   \n",
       "run2            0.541209     0.86877    0.714396    0.761118    0.750833   \n",
       "run3            0.393738    0.843678     0.72649    0.780898    0.767473   \n",
       "run4            0.495636    0.805093    0.816411     0.79574    0.716682   \n",
       "run5            0.412733     0.78845    0.778011    0.745597    0.688521   \n",
       "run6            0.374955    0.759998    0.760721    0.737953    0.682937   \n",
       "run7            0.449164    0.843004    0.691703    0.768386    0.775483   \n",
       "run8            0.320518    0.760072    0.640365    0.714921    0.699422   \n",
       "run9            0.529278    0.787077    0.629437    0.670808    0.724172   \n",
       "r2_test_mean    0.417177    0.799947    0.687647    0.737949     0.70889   \n",
       "r2_test_max     0.541209     0.86877    0.816411     0.79574    0.775483   \n",
       "r2_test_min     0.269883    0.730531    0.551847    0.621344    0.627303   \n",
       "r2_test_std     0.083413    0.041227    0.084217    0.052293    0.045325   \n",
       "\n",
       "                      10          11          12          13          14  \\\n",
       "source            kappa2      kappa3       kier2       kier3    peoevsa6   \n",
       "target        Yield_CO_l  Yield_CO_l  Yield_CO_l  Yield_CO_l  Yield_CO_l   \n",
       "run0            0.743976     0.77899    0.771879    0.623508     0.74919   \n",
       "run1            0.706477    0.709109    0.696214    0.612447    0.434815   \n",
       "run2            0.867585    0.787675    0.812739    0.731423    0.779552   \n",
       "run3            0.828764    0.798319    0.794394    0.769773    0.810217   \n",
       "run4            0.682293    0.736768    0.810371    0.734656    0.729102   \n",
       "run5            0.732981    0.634234    0.667826    0.666916    0.617242   \n",
       "run6            0.813488    0.804161    0.783546    0.749075    0.786008   \n",
       "run7            0.778147    0.791514    0.788254    0.779334    0.754569   \n",
       "run8             0.75557    0.677369    0.759797    0.703394     0.70251   \n",
       "run9            0.758061    0.722292    0.756144    0.714432    0.731896   \n",
       "r2_test_mean    0.766734    0.744043    0.764117    0.708496     0.70951   \n",
       "r2_test_max     0.867585    0.804161    0.812739    0.779334    0.810217   \n",
       "r2_test_min     0.682293    0.634234    0.667826    0.612447    0.434815   \n",
       "r2_test_std     0.053808    0.054944    0.045173    0.054652    0.104599   \n",
       "\n",
       "                      15  \n",
       "source        vsaestate3  \n",
       "target        Yield_CO_l  \n",
       "run0            0.750224  \n",
       "run1            0.540272  \n",
       "run2             0.68947  \n",
       "run3            0.626807  \n",
       "run4            0.708957  \n",
       "run5            0.765446  \n",
       "run6            0.668113  \n",
       "run7            0.733546  \n",
       "run8             0.66079  \n",
       "run9            0.623074  \n",
       "r2_test_mean     0.67667  \n",
       "r2_test_max     0.765446  \n",
       "r2_test_min     0.540272  \n",
       "r2_test_std     0.064824  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_results.T.to_csv('result/result_yield_l.csv', header=False)\n",
    "gen_results.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003f2fe5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
