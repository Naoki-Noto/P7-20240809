{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69652f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\noton\\miniconda3\\envs\\Deep2\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipped loading modules with pytorch-geometric dependency, missing a dependency. No module named 'dgl'\n",
      "Skipped loading some Jax models, missing a dependency. No module named 'jax'\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import tensorflow as tf\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import deepchem as dc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, global_max_pool\n",
    "from torch_geometric.data import Batch, Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66bffaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GCNConv(30, 256)\n",
    "        self.conv2 = GCNConv(256, 256)\n",
    "        self.conv3 = GCNConv(256, 256)\n",
    "        self.conv4 = GCNConv(256, 256)\n",
    "        self.fc1 = nn.Linear(256, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 1)\n",
    "        self.dropout1 = nn.Dropout(p=0.2)\n",
    "        self.dropout2 = nn.Dropout(p=0.2)\n",
    "        self.dropout3 = nn.Dropout(p=0.2)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv4(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = global_max_pool(x, data.batch)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "245051e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate(batch):\n",
    "    data_list, target_list = zip(*batch)\n",
    "    batch_data = Batch.from_data_list(data_list)\n",
    "    batch_target = torch.stack(target_list)\n",
    "    return batch_data, batch_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be45c11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_statistics(group):\n",
    "    r2_test = group['r2_test']\n",
    "    r2_test_dict = {f'run{i}': r2_test_val for i, r2_test_val in enumerate(r2_test)}\n",
    "    return pd.Series({\n",
    "        **r2_test_dict, \n",
    "        'r2_test_mean': np.mean(r2_test),\n",
    "        'r2_test_max': np.max(r2_test),\n",
    "        'r2_test_min': np.min(r2_test),\n",
    "        'r2_test_std': np.std(r2_test, ddof=0),\n",
    "    })\n",
    "\n",
    "def calculate_statistics2(group):\n",
    "    rmse_test = group['rmse_test']\n",
    "    rmse_test_dict = {f'run{i}': rmse_test_val for i, rmse_test_val in enumerate(rmse_test)}\n",
    "    return pd.Series({\n",
    "        **rmse_test_dict, \n",
    "        'rmse_test_mean': np.mean(rmse_test),\n",
    "        'rmse_test_max': np.max(rmse_test),\n",
    "        'rmse_test_min': np.min(rmse_test),\n",
    "        'rmse_test_std': np.std(rmse_test, ddof=0),\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53851fc9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "first_epochs = 50\n",
    "second_epochs = 200\n",
    "second_lr = 9e-3\n",
    "second_wd = 3e-5\n",
    "\n",
    "results_r2 = []\n",
    "results_rmse = []\n",
    "for random_state in range(10):\n",
    "    torch.manual_seed(0)\n",
    "    \n",
    "    for dataset in [\"AI\", \"AI2\", \"Random\", \"Human\"]:\n",
    "        torch.manual_seed(0)\n",
    "        \n",
    "        for t in [\"Yield_CO_l\"]:\n",
    "            torch.manual_seed(0)\n",
    "            df = pd.read_csv('data_Real/data_real.csv')\n",
    "            smiles = df[\"SMILES\"]\n",
    "            featurizer = dc.feat.MolGraphConvFeaturizer(use_edges=True)\n",
    "            X = featurizer.featurize(smiles)\n",
    "            \n",
    "            y = df[t]\n",
    "            data_train, data_test, target_train, target_test = train_test_split(X, y, test_size=0.5, random_state=random_state)\n",
    "\n",
    "            target_train = scaler.fit_transform(target_train.values.reshape(-1, 1)).flatten()\n",
    "            target_test = scaler.transform(target_test.values.reshape(-1, 1)).flatten()\n",
    "            \n",
    "            target_train = torch.tensor(target_train, dtype=torch.float32)\n",
    "            target_test = torch.tensor(target_test, dtype=torch.float32)\n",
    "\n",
    "            data_train_list = []\n",
    "            for graph_data in data_train:\n",
    "                node_features = torch.tensor(graph_data.node_features, dtype=torch.float32)\n",
    "                edge_index = torch.tensor(graph_data.edge_index, dtype=torch.long)\n",
    "                edge_features = torch.tensor(graph_data.edge_features, dtype=torch.float32)\n",
    "                data = Data(x=node_features, edge_index=edge_index, edge_attr=edge_features)\n",
    "                data_train_list.append(data)\n",
    "\n",
    "            data_test_list = []\n",
    "            for graph_data in data_test:\n",
    "                node_features = torch.tensor(graph_data.node_features, dtype=torch.float32)\n",
    "                edge_index = torch.tensor(graph_data.edge_index, dtype=torch.long)\n",
    "                edge_features = torch.tensor(graph_data.edge_features, dtype=torch.float32)\n",
    "                data = Data(x=node_features, edge_index=edge_index, edge_attr=edge_features)\n",
    "                data_test_list.append(data)\n",
    "\n",
    "            train_loader = DataLoader(list(zip(data_train_list, target_train)), batch_size=len(data_train_list), collate_fn=custom_collate)\n",
    "            test_loader = DataLoader(list(zip(data_test_list, target_test)), batch_size=len(data_test_list), collate_fn=custom_collate)\n",
    "\n",
    "            model = Net()\n",
    "            model.load_state_dict(torch.load(f'data_{dataset}/model_{dataset}_sc.pth'))\n",
    "            model.fc3 = nn.Linear(128, 1)\n",
    "        \n",
    "            for param in model.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "            model.train()\n",
    "            optimizer = torch.optim.Adam(model.parameters())\n",
    "            criterion = nn.MSELoss()\n",
    "            \n",
    "            device = torch.device('cpu')\n",
    "            model.to(device)\n",
    "\n",
    "            for epoch in range(first_epochs):\n",
    "                for data, target in train_loader:\n",
    "                    data = data.to(device)\n",
    "                    target = target.to(device)\n",
    "                    with torch.no_grad():\n",
    "                        out = model(data)\n",
    "                        loss = criterion(out, target.view(-1, 1))\n",
    "\n",
    "            for param in model.fc1.parameters():\n",
    "                param.requires_grad = True\n",
    "            for param in model.fc2.parameters():\n",
    "                param.requires_grad = True\n",
    "            for param in model.fc3.parameters():\n",
    "                param.requires_grad = True\n",
    "\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=second_lr, weight_decay=second_wd)\n",
    "\n",
    "            for epoch in range(second_epochs):\n",
    "                for data, target in train_loader:\n",
    "                    data = data.to(device)\n",
    "                    target = target.to(device)\n",
    "                    optimizer.zero_grad()\n",
    "                    out = model(data)\n",
    "                    loss = criterion(out, target.view(-1, 1))\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            model.eval()\n",
    "            pred_train = []\n",
    "            for data, target in train_loader:\n",
    "                data = data.to(device)\n",
    "                with torch.no_grad():\n",
    "                    out = model(data)\n",
    "                pred_train.append(out.cpu().numpy())\n",
    "            pred_train = np.concatenate(pred_train)\n",
    "\n",
    "            pred_test = []\n",
    "            for data, target in test_loader:\n",
    "                data = data.to(device)\n",
    "                with torch.no_grad():\n",
    "                    out = model(data)\n",
    "                pred_test.append(out.cpu().numpy())\n",
    "            pred_test = np.concatenate(pred_test)\n",
    "\n",
    "            pred_train = scaler.inverse_transform(pred_train)\n",
    "            pred_test = scaler.inverse_transform(pred_test)\n",
    "            target_train = scaler.inverse_transform(target_train.numpy().reshape(-1, 1)).flatten()\n",
    "            target_test = scaler.inverse_transform(target_test.numpy().reshape(-1, 1)).flatten()\n",
    "\n",
    "            r2_test_score = metrics.r2_score(target_test, pred_test)\n",
    "            rmse_test_score = metrics.root_mean_squared_error(target_test, pred_test)\n",
    "            results_r2.append({'source': dataset, 'target': t, 'r2_test': r2_test_score})\n",
    "            results_rmse.append({'source': dataset, 'target': t, 'rmse_test': rmse_test_score})\n",
    "\n",
    "results_df = pd.DataFrame(results_r2)\n",
    "gen_results = results_df.groupby(['source', 'target']).apply(calculate_statistics).reset_index()\n",
    "results_df2 = pd.DataFrame(results_rmse)\n",
    "gen_results2 = results_df2.groupby(['source', 'target']).apply(calculate_statistics2).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "463235ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>source</th>\n",
       "      <td>AI</td>\n",
       "      <td>AI2</td>\n",
       "      <td>Human</td>\n",
       "      <td>Random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>Yield_CO_l</td>\n",
       "      <td>Yield_CO_l</td>\n",
       "      <td>Yield_CO_l</td>\n",
       "      <td>Yield_CO_l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run0</th>\n",
       "      <td>0.756797</td>\n",
       "      <td>0.802034</td>\n",
       "      <td>0.770416</td>\n",
       "      <td>0.738409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run1</th>\n",
       "      <td>0.65341</td>\n",
       "      <td>0.611118</td>\n",
       "      <td>0.753812</td>\n",
       "      <td>0.61561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run2</th>\n",
       "      <td>0.771281</td>\n",
       "      <td>0.744335</td>\n",
       "      <td>0.869909</td>\n",
       "      <td>0.789623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run3</th>\n",
       "      <td>0.806017</td>\n",
       "      <td>0.771698</td>\n",
       "      <td>0.792547</td>\n",
       "      <td>0.791772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run4</th>\n",
       "      <td>0.8539</td>\n",
       "      <td>0.831181</td>\n",
       "      <td>0.728561</td>\n",
       "      <td>0.793738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run5</th>\n",
       "      <td>0.797156</td>\n",
       "      <td>0.750136</td>\n",
       "      <td>0.809733</td>\n",
       "      <td>0.751874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run6</th>\n",
       "      <td>0.744194</td>\n",
       "      <td>0.739784</td>\n",
       "      <td>0.78781</td>\n",
       "      <td>0.72423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run7</th>\n",
       "      <td>0.742143</td>\n",
       "      <td>0.760914</td>\n",
       "      <td>0.859839</td>\n",
       "      <td>0.745934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run8</th>\n",
       "      <td>0.670875</td>\n",
       "      <td>0.635723</td>\n",
       "      <td>0.717563</td>\n",
       "      <td>0.707492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run9</th>\n",
       "      <td>0.78908</td>\n",
       "      <td>0.734954</td>\n",
       "      <td>0.711452</td>\n",
       "      <td>0.716503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2_test_mean</th>\n",
       "      <td>0.758485</td>\n",
       "      <td>0.738188</td>\n",
       "      <td>0.780164</td>\n",
       "      <td>0.737519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2_test_max</th>\n",
       "      <td>0.8539</td>\n",
       "      <td>0.831181</td>\n",
       "      <td>0.869909</td>\n",
       "      <td>0.793738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2_test_min</th>\n",
       "      <td>0.65341</td>\n",
       "      <td>0.611118</td>\n",
       "      <td>0.711452</td>\n",
       "      <td>0.61561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2_test_std</th>\n",
       "      <td>0.057575</td>\n",
       "      <td>0.06419</td>\n",
       "      <td>0.052518</td>\n",
       "      <td>0.050476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0           1           2           3\n",
       "source                AI         AI2       Human      Random\n",
       "target        Yield_CO_l  Yield_CO_l  Yield_CO_l  Yield_CO_l\n",
       "run0            0.756797    0.802034    0.770416    0.738409\n",
       "run1             0.65341    0.611118    0.753812     0.61561\n",
       "run2            0.771281    0.744335    0.869909    0.789623\n",
       "run3            0.806017    0.771698    0.792547    0.791772\n",
       "run4              0.8539    0.831181    0.728561    0.793738\n",
       "run5            0.797156    0.750136    0.809733    0.751874\n",
       "run6            0.744194    0.739784     0.78781     0.72423\n",
       "run7            0.742143    0.760914    0.859839    0.745934\n",
       "run8            0.670875    0.635723    0.717563    0.707492\n",
       "run9             0.78908    0.734954    0.711452    0.716503\n",
       "r2_test_mean    0.758485    0.738188    0.780164    0.737519\n",
       "r2_test_max       0.8539    0.831181    0.869909    0.793738\n",
       "r2_test_min      0.65341    0.611118    0.711452     0.61561\n",
       "r2_test_std     0.057575     0.06419    0.052518    0.050476"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_results.T.to_csv('result/result_yield_l_r2.csv', header=False)\n",
    "gen_results.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "003f2fe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>source</th>\n",
       "      <td>AI</td>\n",
       "      <td>AI2</td>\n",
       "      <td>Human</td>\n",
       "      <td>Random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>Yield_CO_l</td>\n",
       "      <td>Yield_CO_l</td>\n",
       "      <td>Yield_CO_l</td>\n",
       "      <td>Yield_CO_l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run0</th>\n",
       "      <td>17.862406</td>\n",
       "      <td>16.115726</td>\n",
       "      <td>17.355053</td>\n",
       "      <td>18.525343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run1</th>\n",
       "      <td>19.376915</td>\n",
       "      <td>20.525131</td>\n",
       "      <td>16.330904</td>\n",
       "      <td>20.406223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run2</th>\n",
       "      <td>18.501642</td>\n",
       "      <td>19.561159</td>\n",
       "      <td>13.953488</td>\n",
       "      <td>17.744255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run3</th>\n",
       "      <td>15.537619</td>\n",
       "      <td>16.856102</td>\n",
       "      <td>16.068014</td>\n",
       "      <td>16.097998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run4</th>\n",
       "      <td>14.18909</td>\n",
       "      <td>15.252479</td>\n",
       "      <td>19.340431</td>\n",
       "      <td>16.859312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run5</th>\n",
       "      <td>15.612196</td>\n",
       "      <td>17.327444</td>\n",
       "      <td>15.120459</td>\n",
       "      <td>17.267082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run6</th>\n",
       "      <td>17.521723</td>\n",
       "      <td>17.672117</td>\n",
       "      <td>15.958216</td>\n",
       "      <td>18.192606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run7</th>\n",
       "      <td>18.737261</td>\n",
       "      <td>18.0424</td>\n",
       "      <td>13.814339</td>\n",
       "      <td>18.599041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run8</th>\n",
       "      <td>20.540039</td>\n",
       "      <td>21.609112</td>\n",
       "      <td>19.027519</td>\n",
       "      <td>19.363775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run9</th>\n",
       "      <td>15.190899</td>\n",
       "      <td>17.028837</td>\n",
       "      <td>17.767801</td>\n",
       "      <td>17.611616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse_test_mean</th>\n",
       "      <td>17.30698</td>\n",
       "      <td>17.99905</td>\n",
       "      <td>16.473621</td>\n",
       "      <td>18.066725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse_test_max</th>\n",
       "      <td>20.540039</td>\n",
       "      <td>21.609112</td>\n",
       "      <td>19.340431</td>\n",
       "      <td>20.406223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse_test_min</th>\n",
       "      <td>14.18909</td>\n",
       "      <td>15.252479</td>\n",
       "      <td>13.814339</td>\n",
       "      <td>16.097998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse_test_std</th>\n",
       "      <td>1.968929</td>\n",
       "      <td>1.890816</td>\n",
       "      <td>1.81376</td>\n",
       "      <td>1.181076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         0           1           2           3\n",
       "source                  AI         AI2       Human      Random\n",
       "target          Yield_CO_l  Yield_CO_l  Yield_CO_l  Yield_CO_l\n",
       "run0             17.862406   16.115726   17.355053   18.525343\n",
       "run1             19.376915   20.525131   16.330904   20.406223\n",
       "run2             18.501642   19.561159   13.953488   17.744255\n",
       "run3             15.537619   16.856102   16.068014   16.097998\n",
       "run4              14.18909   15.252479   19.340431   16.859312\n",
       "run5             15.612196   17.327444   15.120459   17.267082\n",
       "run6             17.521723   17.672117   15.958216   18.192606\n",
       "run7             18.737261     18.0424   13.814339   18.599041\n",
       "run8             20.540039   21.609112   19.027519   19.363775\n",
       "run9             15.190899   17.028837   17.767801   17.611616\n",
       "rmse_test_mean    17.30698    17.99905   16.473621   18.066725\n",
       "rmse_test_max    20.540039   21.609112   19.340431   20.406223\n",
       "rmse_test_min     14.18909   15.252479   13.814339   16.097998\n",
       "rmse_test_std     1.968929    1.890816     1.81376    1.181076"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_results2.T.to_csv('result/result_yield_l_rmse.csv', header=False)\n",
    "gen_results2.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56eeea63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
