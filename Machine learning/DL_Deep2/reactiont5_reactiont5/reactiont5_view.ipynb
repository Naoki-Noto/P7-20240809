{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c6d3b39-5a1c-4b49-9b28-84df92def1d0",
   "metadata": {},
   "source": [
    "This is a notebook to display the results after executing the following commands:\n",
    "```\n",
    "python reactiont5.py\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6afe7a59-e087-4797-9c4a-46d8625689f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\noton\\miniconda3\\envs\\Deep2\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import warnings\n",
    "#import tensorflow as tf\n",
    "from transformers import logging\n",
    "logging.set_verbosity_error()\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "#tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96b558d7-adfd-4628-856d-5908e9d924b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\noton\\miniconda3\\envs\\Deep2\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoTokenizer, T5ForConditionalGeneration, AutoConfig, PreTrainedModel\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from rdkit import Chem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d66df26-fc24-450d-8145-62e26fe68044",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReactionT5Yield(PreTrainedModel):\n",
    "    config_class  = AutoConfig\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.config = config\n",
    "        self.model = T5ForConditionalGeneration.from_pretrained(self.config._name_or_path)\n",
    "        self.model.resize_token_embeddings(self.config.vocab_size)\n",
    "        self.fc1 = nn.Linear(self.config.hidden_size, self.config.hidden_size//2)\n",
    "        self.fc2 = nn.Linear(self.config.hidden_size, self.config.hidden_size//2)\n",
    "        self.fc3 = nn.Linear(self.config.hidden_size//2*2, self.config.hidden_size)\n",
    "        self.fc4 = nn.Linear(self.config.hidden_size, self.config.hidden_size)\n",
    "        self.fc5 = nn.Linear(self.config.hidden_size, 1)\n",
    "\n",
    "        self._init_weights(self.fc1)\n",
    "        self._init_weights(self.fc2)\n",
    "        self._init_weights(self.fc3)\n",
    "        self._init_weights(self.fc4)\n",
    "        self._init_weights(self.fc5)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=0.01)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=0.01)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        inputs = {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask\n",
    "            }\n",
    "        encoder_outputs = self.model.encoder(**inputs)\n",
    "        encoder_hidden_states = encoder_outputs[0]\n",
    "        outputs = self.model.decoder(input_ids=torch.full((input_ids.size(0), 1),\n",
    "                                                          self.config.decoder_start_token_id,\n",
    "                                                          dtype=torch.long).to(input_ids.device),\n",
    "                                     encoder_hidden_states=encoder_hidden_states)\n",
    "        last_hidden_states = outputs[0]\n",
    "        output1 = self.fc1(last_hidden_states[:, 0, :]) #.view(-1, self.config.hidden_size)削除\n",
    "        output2 = self.fc2(encoder_hidden_states[:, 0, :]) #.view(-1, self.config.hidden_size)削除\n",
    "        output = self.fc3(torch.hstack((output1, output2)))\n",
    "        output = self.fc4(output)\n",
    "        output = self.fc5(output)\n",
    "        return output * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a48f1c70-7cc0-45d8-9293-24c0919570d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate(batch):\n",
    "    data_list, target_list = zip(*batch)\n",
    "    batch_data = {key: torch.stack([d[key] for d in data_list]) for key in data_list[0]}\n",
    "    batch_target = torch.stack(target_list)\n",
    "    return batch_data, batch_target\n",
    "\n",
    "class ReactionT5Dataset(Dataset):\n",
    "    def __init__(self, input_ids, attention_masks, targets):\n",
    "        self.input_ids = input_ids\n",
    "        self.attention_masks = attention_masks\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': torch.tensor(self.input_ids[idx], dtype=torch.long).clone().detach(),\n",
    "            'attention_mask': torch.tensor(self.attention_masks[idx], dtype=torch.long).clone().detach()\n",
    "        }, torch.tensor(self.targets[idx], dtype=torch.float32).clone().detach()\n",
    "\n",
    "def canonicalize(smiles):\n",
    "    try:\n",
    "        new_smiles = Chem.MolToSmiles(Chem.MolFromSmiles(smiles), canonical=True)\n",
    "    except:\n",
    "        new_smiles = None\n",
    "    return new_smiles\n",
    "\n",
    "def make_input_list(react, prod, smiles_list):\n",
    "    input_list = []\n",
    "    for ops in smiles_list:\n",
    "        canonicalize_ops = canonicalize(ops)\n",
    "        if canonicalize_ops == None:\n",
    "            print(f'{ops} is not canonicalized')\n",
    "        input_list.append('REACTANT:' + react + 'REAGENT:' + canonicalize_ops + 'PRODUCT:' + prod)\n",
    "    return input_list\n",
    "\n",
    "def tokenize_smiles(smiles_list):\n",
    "    encodings = tokenizer(smiles_list, padding=True, truncation=True, max_length=300, return_tensors=\"pt\")\n",
    "    return encodings['input_ids'].tolist(), encodings['attention_mask'].tolist()\n",
    "\n",
    "def calculate_statistics(group):\n",
    "    r2_test = group['r2_test']\n",
    "    r2_test_dict = {f'run{i}': r2_test_val for i, r2_test_val in enumerate(r2_test)}\n",
    "    return pd.Series({\n",
    "        **r2_test_dict,\n",
    "        'r2_test_mean': np.mean(r2_test),\n",
    "        'r2_test_max': np.max(r2_test),\n",
    "        'r2_test_min': np.min(r2_test),\n",
    "        'r2_test_std': np.std(r2_test, ddof=0),\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74df3e45-bc4a-4016-814f-7ade2c9bf6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "o=pickle.load(open(\"results.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb8e81ac-6dee-49c0-be99-4088d662ba2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>Yield_CO_cl</td>\n",
       "      <td>Yield_CO_l</td>\n",
       "      <td>Yield_CO_s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run0</th>\n",
       "      <td>0.504806</td>\n",
       "      <td>0.604748</td>\n",
       "      <td>0.299739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run1</th>\n",
       "      <td>0.461216</td>\n",
       "      <td>0.53812</td>\n",
       "      <td>0.207225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run2</th>\n",
       "      <td>0.608692</td>\n",
       "      <td>0.58839</td>\n",
       "      <td>0.243142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run3</th>\n",
       "      <td>0.60022</td>\n",
       "      <td>0.671486</td>\n",
       "      <td>0.719229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run4</th>\n",
       "      <td>0.603094</td>\n",
       "      <td>0.510813</td>\n",
       "      <td>0.367751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run5</th>\n",
       "      <td>0.40864</td>\n",
       "      <td>0.38099</td>\n",
       "      <td>0.502642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run6</th>\n",
       "      <td>0.629278</td>\n",
       "      <td>0.538695</td>\n",
       "      <td>0.241459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run7</th>\n",
       "      <td>0.483289</td>\n",
       "      <td>0.586654</td>\n",
       "      <td>0.485936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run8</th>\n",
       "      <td>0.292545</td>\n",
       "      <td>0.457376</td>\n",
       "      <td>0.541093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run9</th>\n",
       "      <td>0.306992</td>\n",
       "      <td>0.480833</td>\n",
       "      <td>0.254934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2_test_mean</th>\n",
       "      <td>0.489877</td>\n",
       "      <td>0.53581</td>\n",
       "      <td>0.386315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2_test_max</th>\n",
       "      <td>0.629278</td>\n",
       "      <td>0.671486</td>\n",
       "      <td>0.719229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2_test_min</th>\n",
       "      <td>0.292545</td>\n",
       "      <td>0.38099</td>\n",
       "      <td>0.207225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2_test_std</th>\n",
       "      <td>0.117736</td>\n",
       "      <td>0.078925</td>\n",
       "      <td>0.160281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        0           1           2\n",
       "target        Yield_CO_cl  Yield_CO_l  Yield_CO_s\n",
       "run0             0.504806    0.604748    0.299739\n",
       "run1             0.461216     0.53812    0.207225\n",
       "run2             0.608692     0.58839    0.243142\n",
       "run3              0.60022    0.671486    0.719229\n",
       "run4             0.603094    0.510813    0.367751\n",
       "run5              0.40864     0.38099    0.502642\n",
       "run6             0.629278    0.538695    0.241459\n",
       "run7             0.483289    0.586654    0.485936\n",
       "run8             0.292545    0.457376    0.541093\n",
       "run9             0.306992    0.480833    0.254934\n",
       "r2_test_mean     0.489877     0.53581    0.386315\n",
       "r2_test_max      0.629278    0.671486    0.719229\n",
       "r2_test_min      0.292545     0.38099    0.207225\n",
       "r2_test_std      0.117736    0.078925    0.160281"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "results_df = pd.DataFrame(o)\n",
    "gen_results = results_df.groupby(['target']).apply(calculate_statistics).reset_index()\n",
    "gen_results.T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
