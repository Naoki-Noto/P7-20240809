{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69652f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\noton\\miniconda3\\envs\\Deep2\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipped loading modules with pytorch-geometric dependency, missing a dependency. No module named 'dgl'\n",
      "Skipped loading some Jax models, missing a dependency. No module named 'jax'\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import tensorflow as tf\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import deepchem as dc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, global_max_pool\n",
    "from torch_geometric.data import Batch, Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66bffaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GCNConv(30, 256)\n",
    "        self.conv2 = GCNConv(256, 256)\n",
    "        self.conv3 = GCNConv(256, 256)\n",
    "        self.conv4 = GCNConv(256, 256)\n",
    "        self.fc1 = nn.Linear(256, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 1)\n",
    "        self.dropout1 = nn.Dropout(p=0.15)\n",
    "        self.dropout2 = nn.Dropout(p=0.3)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv4(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = global_max_pool(x, data.batch)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "245051e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate(batch):\n",
    "    data_list, target_list = zip(*batch)\n",
    "    batch_data = Batch.from_data_list(data_list)\n",
    "    batch_target = torch.stack(target_list)\n",
    "    return batch_data, batch_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be45c11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_statistics(group):\n",
    "    r2_test = group['r2_test']\n",
    "    r2_test_dict = {f'run{i}': r2_test_val for i, r2_test_val in enumerate(r2_test)}\n",
    "    return pd.Series({\n",
    "        **r2_test_dict, \n",
    "        'r2_test_mean': np.mean(r2_test),\n",
    "        'r2_test_max': np.max(r2_test),\n",
    "        'r2_test_min': np.min(r2_test),\n",
    "        'r2_test_std': np.std(r2_test, ddof=0),\n",
    "    })\n",
    "\n",
    "def calculate_statistics2(group):\n",
    "    rmse_test = group['rmse_test']\n",
    "    rmse_test_dict = {f'run{i}': rmse_test_val for i, rmse_test_val in enumerate(rmse_test)}\n",
    "    return pd.Series({\n",
    "        **rmse_test_dict, \n",
    "        'rmse_test_mean': np.mean(rmse_test),\n",
    "        'rmse_test_max': np.max(rmse_test),\n",
    "        'rmse_test_min': np.min(rmse_test),\n",
    "        'rmse_test_std': np.std(rmse_test, ddof=0),\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53851fc9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "first_epochs = 40\n",
    "second_epochs = 180\n",
    "second_lr = 3e-3\n",
    "second_wd = 7e-4\n",
    "\n",
    "results_r2 = []\n",
    "results_rmse = []\n",
    "for random_state in range(10):\n",
    "    torch.manual_seed(0)\n",
    "    \n",
    "    for dataset in [\"AI\", \"AI2\", \"Random\", \"Human\"]:\n",
    "        torch.manual_seed(0)\n",
    "        \n",
    "        for t in [\"Yield_CO_cl\"]:\n",
    "            torch.manual_seed(0)\n",
    "            scaler = StandardScaler()\n",
    "            df = pd.read_csv('data_Real/data_real.csv')\n",
    "            smiles = df[\"SMILES\"]\n",
    "            featurizer = dc.feat.MolGraphConvFeaturizer(use_edges=True)\n",
    "            X = featurizer.featurize(smiles)\n",
    "            \n",
    "            y = df[t]\n",
    "            data_train, data_test, target_train, target_test = train_test_split(X, y, test_size=0.5, random_state=random_state)\n",
    "\n",
    "            target_train = scaler.fit_transform(target_train.values.reshape(-1, 1)).flatten()\n",
    "            target_test = scaler.transform(target_test.values.reshape(-1, 1)).flatten()\n",
    "            \n",
    "            target_train = torch.tensor(target_train, dtype=torch.float32)\n",
    "            target_test = torch.tensor(target_test, dtype=torch.float32)\n",
    "\n",
    "            data_train_list = []\n",
    "            for graph_data in data_train:\n",
    "                node_features = torch.tensor(graph_data.node_features, dtype=torch.float32)\n",
    "                edge_index = torch.tensor(graph_data.edge_index, dtype=torch.long)\n",
    "                edge_features = torch.tensor(graph_data.edge_features, dtype=torch.float32)\n",
    "                data = Data(x=node_features, edge_index=edge_index, edge_attr=edge_features)\n",
    "                data_train_list.append(data)\n",
    "\n",
    "            data_test_list = []\n",
    "            for graph_data in data_test:\n",
    "                node_features = torch.tensor(graph_data.node_features, dtype=torch.float32)\n",
    "                edge_index = torch.tensor(graph_data.edge_index, dtype=torch.long)\n",
    "                edge_features = torch.tensor(graph_data.edge_features, dtype=torch.float32)\n",
    "                data = Data(x=node_features, edge_index=edge_index, edge_attr=edge_features)\n",
    "                data_test_list.append(data)\n",
    "\n",
    "            train_loader = DataLoader(list(zip(data_train_list, target_train)), batch_size=len(data_train_list), collate_fn=custom_collate)\n",
    "            test_loader = DataLoader(list(zip(data_test_list, target_test)), batch_size=len(data_test_list), collate_fn=custom_collate)\n",
    "\n",
    "            model = Net()\n",
    "            model.load_state_dict(torch.load(f'data_{dataset}/model_{dataset}_sc.pth'))\n",
    "            model.fc3 = nn.Linear(128, 1)\n",
    "        \n",
    "            for param in model.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "            model.train()\n",
    "            optimizer = torch.optim.Adam(model.parameters())\n",
    "            criterion = nn.MSELoss()\n",
    "            \n",
    "            device = torch.device('cpu')\n",
    "            model.to(device)\n",
    "\n",
    "            for epoch in range(first_epochs):\n",
    "                for data, target in train_loader:\n",
    "                    data = data.to(device)\n",
    "                    target = target.to(device)\n",
    "                    with torch.no_grad():\n",
    "                        out = model(data)\n",
    "                        loss = criterion(out, target.view(-1, 1))\n",
    "\n",
    "            for param in model.fc1.parameters():\n",
    "                param.requires_grad = True\n",
    "            for param in model.fc2.parameters():\n",
    "                param.requires_grad = True\n",
    "            for param in model.fc3.parameters():\n",
    "                param.requires_grad = True\n",
    "\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=second_lr, weight_decay=second_wd)\n",
    "\n",
    "            for epoch in range(second_epochs):\n",
    "                for data, target in train_loader:\n",
    "                    data = data.to(device)\n",
    "                    target = target.to(device)\n",
    "                    optimizer.zero_grad()\n",
    "                    out = model(data)\n",
    "                    loss = criterion(out, target.view(-1, 1))\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            model.eval()\n",
    "            pred_train = []\n",
    "            for data, target in train_loader:\n",
    "                data = data.to(device)\n",
    "                with torch.no_grad():\n",
    "                    out = model(data)\n",
    "                pred_train.append(out.cpu().numpy())\n",
    "            pred_train = np.concatenate(pred_train)\n",
    "\n",
    "            pred_test = []\n",
    "            for data, target in test_loader:\n",
    "                data = data.to(device)\n",
    "                with torch.no_grad():\n",
    "                    out = model(data)\n",
    "                pred_test.append(out.cpu().numpy())\n",
    "            pred_test = np.concatenate(pred_test)\n",
    "\n",
    "            pred_train = scaler.inverse_transform(pred_train)\n",
    "            pred_test = scaler.inverse_transform(pred_test)\n",
    "            target_train = scaler.inverse_transform(target_train.numpy().reshape(-1, 1)).flatten()\n",
    "            target_test = scaler.inverse_transform(target_test.numpy().reshape(-1, 1)).flatten()\n",
    "\n",
    "            r2_test_score = metrics.r2_score(target_test, pred_test)\n",
    "            rmse_test_score = metrics.root_mean_squared_error(target_test, pred_test)\n",
    "            results_r2.append({'source': dataset, 'target': t, 'r2_test': r2_test_score})\n",
    "            results_rmse.append({'source': dataset, 'target': t, 'rmse_test': rmse_test_score})\n",
    "\n",
    "results_df = pd.DataFrame(results_r2)\n",
    "gen_results = results_df.groupby(['source', 'target']).apply(calculate_statistics).reset_index()\n",
    "results_df2 = pd.DataFrame(results_rmse)\n",
    "gen_results2 = results_df2.groupby(['source', 'target']).apply(calculate_statistics2).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "463235ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>source</th>\n",
       "      <td>AI</td>\n",
       "      <td>AI2</td>\n",
       "      <td>Human</td>\n",
       "      <td>Random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>Yield_CO_cl</td>\n",
       "      <td>Yield_CO_cl</td>\n",
       "      <td>Yield_CO_cl</td>\n",
       "      <td>Yield_CO_cl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run0</th>\n",
       "      <td>0.686809</td>\n",
       "      <td>0.70551</td>\n",
       "      <td>0.551521</td>\n",
       "      <td>0.720212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run1</th>\n",
       "      <td>0.685759</td>\n",
       "      <td>0.596859</td>\n",
       "      <td>0.718404</td>\n",
       "      <td>0.657447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run2</th>\n",
       "      <td>0.410787</td>\n",
       "      <td>0.59265</td>\n",
       "      <td>0.542277</td>\n",
       "      <td>0.55004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run3</th>\n",
       "      <td>0.746571</td>\n",
       "      <td>0.680504</td>\n",
       "      <td>0.723074</td>\n",
       "      <td>0.786152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run4</th>\n",
       "      <td>0.807778</td>\n",
       "      <td>0.760319</td>\n",
       "      <td>0.770936</td>\n",
       "      <td>0.788007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run5</th>\n",
       "      <td>0.717081</td>\n",
       "      <td>0.679512</td>\n",
       "      <td>0.761488</td>\n",
       "      <td>0.691334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run6</th>\n",
       "      <td>0.683648</td>\n",
       "      <td>0.625471</td>\n",
       "      <td>0.785901</td>\n",
       "      <td>0.644469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run7</th>\n",
       "      <td>0.688122</td>\n",
       "      <td>0.670355</td>\n",
       "      <td>0.784468</td>\n",
       "      <td>0.731901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run8</th>\n",
       "      <td>0.389784</td>\n",
       "      <td>0.355029</td>\n",
       "      <td>0.34964</td>\n",
       "      <td>0.382558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run9</th>\n",
       "      <td>0.602396</td>\n",
       "      <td>0.578787</td>\n",
       "      <td>0.553459</td>\n",
       "      <td>0.528111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2_test_mean</th>\n",
       "      <td>0.641873</td>\n",
       "      <td>0.6245</td>\n",
       "      <td>0.654117</td>\n",
       "      <td>0.648023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2_test_max</th>\n",
       "      <td>0.807778</td>\n",
       "      <td>0.760319</td>\n",
       "      <td>0.785901</td>\n",
       "      <td>0.788007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2_test_min</th>\n",
       "      <td>0.389784</td>\n",
       "      <td>0.355029</td>\n",
       "      <td>0.34964</td>\n",
       "      <td>0.382558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2_test_std</th>\n",
       "      <td>0.130568</td>\n",
       "      <td>0.104766</td>\n",
       "      <td>0.139389</td>\n",
       "      <td>0.121388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        0            1            2            3\n",
       "source                 AI          AI2        Human       Random\n",
       "target        Yield_CO_cl  Yield_CO_cl  Yield_CO_cl  Yield_CO_cl\n",
       "run0             0.686809      0.70551     0.551521     0.720212\n",
       "run1             0.685759     0.596859     0.718404     0.657447\n",
       "run2             0.410787      0.59265     0.542277      0.55004\n",
       "run3             0.746571     0.680504     0.723074     0.786152\n",
       "run4             0.807778     0.760319     0.770936     0.788007\n",
       "run5             0.717081     0.679512     0.761488     0.691334\n",
       "run6             0.683648     0.625471     0.785901     0.644469\n",
       "run7             0.688122     0.670355     0.784468     0.731901\n",
       "run8             0.389784     0.355029      0.34964     0.382558\n",
       "run9             0.602396     0.578787     0.553459     0.528111\n",
       "r2_test_mean     0.641873       0.6245     0.654117     0.648023\n",
       "r2_test_max      0.807778     0.760319     0.785901     0.788007\n",
       "r2_test_min      0.389784     0.355029      0.34964     0.382558\n",
       "r2_test_std      0.130568     0.104766     0.139389     0.121388"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_results.T.to_csv('result/result_yield_cl_r2.csv', header=False)\n",
    "gen_results.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "003f2fe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>source</th>\n",
       "      <td>AI</td>\n",
       "      <td>AI2</td>\n",
       "      <td>Human</td>\n",
       "      <td>Random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>Yield_CO_cl</td>\n",
       "      <td>Yield_CO_cl</td>\n",
       "      <td>Yield_CO_cl</td>\n",
       "      <td>Yield_CO_cl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run0</th>\n",
       "      <td>10.842232</td>\n",
       "      <td>10.513538</td>\n",
       "      <td>12.974327</td>\n",
       "      <td>10.247752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run1</th>\n",
       "      <td>9.115283</td>\n",
       "      <td>10.324457</td>\n",
       "      <td>8.628842</td>\n",
       "      <td>9.517065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run2</th>\n",
       "      <td>15.251168</td>\n",
       "      <td>12.680916</td>\n",
       "      <td>13.442126</td>\n",
       "      <td>13.327661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run3</th>\n",
       "      <td>9.737706</td>\n",
       "      <td>10.933557</td>\n",
       "      <td>10.179125</td>\n",
       "      <td>8.945034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run4</th>\n",
       "      <td>8.61164</td>\n",
       "      <td>9.616161</td>\n",
       "      <td>9.400773</td>\n",
       "      <td>9.043684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run5</th>\n",
       "      <td>9.256089</td>\n",
       "      <td>9.851503</td>\n",
       "      <td>8.498686</td>\n",
       "      <td>9.668088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run6</th>\n",
       "      <td>10.104265</td>\n",
       "      <td>10.994164</td>\n",
       "      <td>8.312396</td>\n",
       "      <td>10.711694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run7</th>\n",
       "      <td>10.627842</td>\n",
       "      <td>10.926357</td>\n",
       "      <td>8.83503</td>\n",
       "      <td>9.853713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run8</th>\n",
       "      <td>13.485733</td>\n",
       "      <td>13.864458</td>\n",
       "      <td>13.922258</td>\n",
       "      <td>13.565336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run9</th>\n",
       "      <td>10.300327</td>\n",
       "      <td>10.601723</td>\n",
       "      <td>10.915811</td>\n",
       "      <td>11.221355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse_test_mean</th>\n",
       "      <td>10.733229</td>\n",
       "      <td>11.030684</td>\n",
       "      <td>10.510937</td>\n",
       "      <td>10.610138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse_test_max</th>\n",
       "      <td>15.251168</td>\n",
       "      <td>13.864458</td>\n",
       "      <td>13.922258</td>\n",
       "      <td>13.565336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse_test_min</th>\n",
       "      <td>8.61164</td>\n",
       "      <td>9.616161</td>\n",
       "      <td>8.312396</td>\n",
       "      <td>8.945034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse_test_std</th>\n",
       "      <td>1.971952</td>\n",
       "      <td>1.229501</td>\n",
       "      <td>2.074547</td>\n",
       "      <td>1.565699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          0            1            2            3\n",
       "source                   AI          AI2        Human       Random\n",
       "target          Yield_CO_cl  Yield_CO_cl  Yield_CO_cl  Yield_CO_cl\n",
       "run0              10.842232    10.513538    12.974327    10.247752\n",
       "run1               9.115283    10.324457     8.628842     9.517065\n",
       "run2              15.251168    12.680916    13.442126    13.327661\n",
       "run3               9.737706    10.933557    10.179125     8.945034\n",
       "run4                8.61164     9.616161     9.400773     9.043684\n",
       "run5               9.256089     9.851503     8.498686     9.668088\n",
       "run6              10.104265    10.994164     8.312396    10.711694\n",
       "run7              10.627842    10.926357      8.83503     9.853713\n",
       "run8              13.485733    13.864458    13.922258    13.565336\n",
       "run9              10.300327    10.601723    10.915811    11.221355\n",
       "rmse_test_mean    10.733229    11.030684    10.510937    10.610138\n",
       "rmse_test_max     15.251168    13.864458    13.922258    13.565336\n",
       "rmse_test_min       8.61164     9.616161     8.312396     8.945034\n",
       "rmse_test_std      1.971952     1.229501     2.074547     1.565699"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_results2.T.to_csv('result/result_yield_cl_rmse.csv', header=False)\n",
    "gen_results2.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22ed63d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
