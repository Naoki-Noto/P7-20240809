{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69652f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\noton\\miniconda3\\envs\\Deep2\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipped loading modules with pytorch-geometric dependency, missing a dependency. No module named 'dgl'\n",
      "Skipped loading some Jax models, missing a dependency. No module named 'jax'\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import tensorflow as tf\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import deepchem as dc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, global_max_pool\n",
    "from torch_geometric.data import Batch, Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66bffaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GCNConv(30, 256)\n",
    "        self.conv2 = GCNConv(256, 256)\n",
    "        self.conv3 = GCNConv(256, 256)\n",
    "        self.conv4 = GCNConv(256, 256)\n",
    "        self.fc1 = nn.Linear(256, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 1)\n",
    "        self.dropout1 = nn.Dropout(p=0.15)\n",
    "        self.dropout2 = nn.Dropout(p=0.3)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv4(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = global_max_pool(x, data.batch)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "245051e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate(batch):\n",
    "    data_list, target_list = zip(*batch)\n",
    "    batch_data = Batch.from_data_list(data_list)\n",
    "    batch_target = torch.stack(target_list)\n",
    "    return batch_data, batch_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be45c11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_statistics(group):\n",
    "    r2_test = group['r2_test']\n",
    "    r2_test_dict = {f'run{i}': r2_test_val for i, r2_test_val in enumerate(r2_test)}\n",
    "    return pd.Series({\n",
    "        **r2_test_dict, \n",
    "        'r2_test_mean': np.mean(r2_test),\n",
    "        'r2_test_max': np.max(r2_test),\n",
    "        'r2_test_min': np.min(r2_test),\n",
    "        'r2_test_std': np.std(r2_test, ddof=0),\n",
    "    })\n",
    "\n",
    "def calculate_statistics2(group):\n",
    "    rmse_test = group['rmse_test']\n",
    "    rmse_test_dict = {f'run{i}': rmse_test_val for i, rmse_test_val in enumerate(rmse_test)}\n",
    "    return pd.Series({\n",
    "        **rmse_test_dict, \n",
    "        'rmse_test_mean': np.mean(rmse_test),\n",
    "        'rmse_test_max': np.max(rmse_test),\n",
    "        'rmse_test_min': np.min(rmse_test),\n",
    "        'rmse_test_std': np.std(rmse_test, ddof=0),\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53851fc9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "first_epochs = 50\n",
    "second_epochs = 200\n",
    "second_lr = 9e-3\n",
    "second_wd = 0\n",
    "\n",
    "results_r2 = []\n",
    "results_rmse = []\n",
    "for random_state in range(10):\n",
    "    torch.manual_seed(0)\n",
    "    \n",
    "    for dataset in [\"AI\", \"AI2\", \"Random\", \"Human\"]:\n",
    "        torch.manual_seed(0)\n",
    "        \n",
    "        for t in [\"Yield_CO_l\"]:\n",
    "            torch.manual_seed(0)\n",
    "            scaler = StandardScaler()\n",
    "            df = pd.read_csv('data_Real/data_real.csv')\n",
    "            smiles = df[\"SMILES\"]\n",
    "            featurizer = dc.feat.MolGraphConvFeaturizer(use_edges=True)\n",
    "            X = featurizer.featurize(smiles)\n",
    "            \n",
    "            y = df[t]\n",
    "            data_train, data_test, target_train, target_test = train_test_split(X, y, test_size=0.5, random_state=random_state)\n",
    "\n",
    "            target_train = scaler.fit_transform(target_train.values.reshape(-1, 1)).flatten()\n",
    "            target_test = scaler.transform(target_test.values.reshape(-1, 1)).flatten()\n",
    "            \n",
    "            target_train = torch.tensor(target_train, dtype=torch.float32)\n",
    "            target_test = torch.tensor(target_test, dtype=torch.float32)\n",
    "\n",
    "            data_train_list = []\n",
    "            for graph_data in data_train:\n",
    "                node_features = torch.tensor(graph_data.node_features, dtype=torch.float32)\n",
    "                edge_index = torch.tensor(graph_data.edge_index, dtype=torch.long)\n",
    "                edge_features = torch.tensor(graph_data.edge_features, dtype=torch.float32)\n",
    "                data = Data(x=node_features, edge_index=edge_index, edge_attr=edge_features)\n",
    "                data_train_list.append(data)\n",
    "\n",
    "            data_test_list = []\n",
    "            for graph_data in data_test:\n",
    "                node_features = torch.tensor(graph_data.node_features, dtype=torch.float32)\n",
    "                edge_index = torch.tensor(graph_data.edge_index, dtype=torch.long)\n",
    "                edge_features = torch.tensor(graph_data.edge_features, dtype=torch.float32)\n",
    "                data = Data(x=node_features, edge_index=edge_index, edge_attr=edge_features)\n",
    "                data_test_list.append(data)\n",
    "\n",
    "            train_loader = DataLoader(list(zip(data_train_list, target_train)), batch_size=len(data_train_list), collate_fn=custom_collate)\n",
    "            test_loader = DataLoader(list(zip(data_test_list, target_test)), batch_size=len(data_test_list), collate_fn=custom_collate)\n",
    "\n",
    "            model = Net()\n",
    "            model.load_state_dict(torch.load(f'data_{dataset}/model_{dataset}_sc.pth'))\n",
    "            model.fc3 = nn.Linear(128, 1)\n",
    "        \n",
    "            for param in model.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "            model.train()\n",
    "            optimizer = torch.optim.Adam(model.parameters())\n",
    "            criterion = nn.MSELoss()\n",
    "            \n",
    "            device = torch.device('cpu')\n",
    "            model.to(device)\n",
    "\n",
    "            for epoch in range(first_epochs):\n",
    "                for data, target in train_loader:\n",
    "                    data = data.to(device)\n",
    "                    target = target.to(device)\n",
    "                    with torch.no_grad():\n",
    "                        out = model(data)\n",
    "                        loss = criterion(out, target.view(-1, 1))\n",
    "\n",
    "            for param in model.fc1.parameters():\n",
    "                param.requires_grad = True\n",
    "            for param in model.fc2.parameters():\n",
    "                param.requires_grad = True\n",
    "            for param in model.fc3.parameters():\n",
    "                param.requires_grad = True\n",
    "\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=second_lr, weight_decay=second_wd)\n",
    "\n",
    "            for epoch in range(second_epochs):\n",
    "                for data, target in train_loader:\n",
    "                    data = data.to(device)\n",
    "                    target = target.to(device)\n",
    "                    optimizer.zero_grad()\n",
    "                    out = model(data)\n",
    "                    loss = criterion(out, target.view(-1, 1))\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            model.eval()\n",
    "            pred_train = []\n",
    "            for data, target in train_loader:\n",
    "                data = data.to(device)\n",
    "                with torch.no_grad():\n",
    "                    out = model(data)\n",
    "                pred_train.append(out.cpu().numpy())\n",
    "            pred_train = np.concatenate(pred_train)\n",
    "\n",
    "            pred_test = []\n",
    "            for data, target in test_loader:\n",
    "                data = data.to(device)\n",
    "                with torch.no_grad():\n",
    "                    out = model(data)\n",
    "                pred_test.append(out.cpu().numpy())\n",
    "            pred_test = np.concatenate(pred_test)\n",
    "\n",
    "            pred_train = scaler.inverse_transform(pred_train)\n",
    "            pred_test = scaler.inverse_transform(pred_test)\n",
    "            target_train = scaler.inverse_transform(target_train.numpy().reshape(-1, 1)).flatten()\n",
    "            target_test = scaler.inverse_transform(target_test.numpy().reshape(-1, 1)).flatten()\n",
    "\n",
    "            r2_test_score = metrics.r2_score(target_test, pred_test)\n",
    "            rmse_test_score = metrics.root_mean_squared_error(target_test, pred_test)\n",
    "            results_r2.append({'source': dataset, 'target': t, 'r2_test': r2_test_score})\n",
    "            results_rmse.append({'source': dataset, 'target': t, 'rmse_test': rmse_test_score})\n",
    "\n",
    "results_df = pd.DataFrame(results_r2)\n",
    "gen_results = results_df.groupby(['source', 'target']).apply(calculate_statistics).reset_index()\n",
    "results_df2 = pd.DataFrame(results_rmse)\n",
    "gen_results2 = results_df2.groupby(['source', 'target']).apply(calculate_statistics2).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "463235ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>source</th>\n",
       "      <td>AI</td>\n",
       "      <td>AI2</td>\n",
       "      <td>Human</td>\n",
       "      <td>Random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>Yield_CO_l</td>\n",
       "      <td>Yield_CO_l</td>\n",
       "      <td>Yield_CO_l</td>\n",
       "      <td>Yield_CO_l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run0</th>\n",
       "      <td>0.787599</td>\n",
       "      <td>0.724015</td>\n",
       "      <td>0.782205</td>\n",
       "      <td>0.747732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run1</th>\n",
       "      <td>0.712974</td>\n",
       "      <td>0.672684</td>\n",
       "      <td>0.721607</td>\n",
       "      <td>0.549856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run2</th>\n",
       "      <td>0.823474</td>\n",
       "      <td>0.766033</td>\n",
       "      <td>0.883678</td>\n",
       "      <td>0.838445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run3</th>\n",
       "      <td>0.810607</td>\n",
       "      <td>0.763249</td>\n",
       "      <td>0.684141</td>\n",
       "      <td>0.799306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run4</th>\n",
       "      <td>0.8758</td>\n",
       "      <td>0.832128</td>\n",
       "      <td>0.719592</td>\n",
       "      <td>0.808316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run5</th>\n",
       "      <td>0.796173</td>\n",
       "      <td>0.734981</td>\n",
       "      <td>0.779827</td>\n",
       "      <td>0.764103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run6</th>\n",
       "      <td>0.810243</td>\n",
       "      <td>0.772656</td>\n",
       "      <td>0.80199</td>\n",
       "      <td>0.759365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run7</th>\n",
       "      <td>0.752158</td>\n",
       "      <td>0.795167</td>\n",
       "      <td>0.849634</td>\n",
       "      <td>0.791585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run8</th>\n",
       "      <td>0.714375</td>\n",
       "      <td>0.704101</td>\n",
       "      <td>0.720947</td>\n",
       "      <td>0.726884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run9</th>\n",
       "      <td>0.759791</td>\n",
       "      <td>0.753148</td>\n",
       "      <td>0.683541</td>\n",
       "      <td>0.652717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2_test_mean</th>\n",
       "      <td>0.784319</td>\n",
       "      <td>0.751816</td>\n",
       "      <td>0.762716</td>\n",
       "      <td>0.743831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2_test_max</th>\n",
       "      <td>0.8758</td>\n",
       "      <td>0.832128</td>\n",
       "      <td>0.883678</td>\n",
       "      <td>0.838445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2_test_min</th>\n",
       "      <td>0.712974</td>\n",
       "      <td>0.672684</td>\n",
       "      <td>0.683541</td>\n",
       "      <td>0.549856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2_test_std</th>\n",
       "      <td>0.047994</td>\n",
       "      <td>0.043235</td>\n",
       "      <td>0.064914</td>\n",
       "      <td>0.08084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0           1           2           3\n",
       "source                AI         AI2       Human      Random\n",
       "target        Yield_CO_l  Yield_CO_l  Yield_CO_l  Yield_CO_l\n",
       "run0            0.787599    0.724015    0.782205    0.747732\n",
       "run1            0.712974    0.672684    0.721607    0.549856\n",
       "run2            0.823474    0.766033    0.883678    0.838445\n",
       "run3            0.810607    0.763249    0.684141    0.799306\n",
       "run4              0.8758    0.832128    0.719592    0.808316\n",
       "run5            0.796173    0.734981    0.779827    0.764103\n",
       "run6            0.810243    0.772656     0.80199    0.759365\n",
       "run7            0.752158    0.795167    0.849634    0.791585\n",
       "run8            0.714375    0.704101    0.720947    0.726884\n",
       "run9            0.759791    0.753148    0.683541    0.652717\n",
       "r2_test_mean    0.784319    0.751816    0.762716    0.743831\n",
       "r2_test_max       0.8758    0.832128    0.883678    0.838445\n",
       "r2_test_min     0.712974    0.672684    0.683541    0.549856\n",
       "r2_test_std     0.047994    0.043235    0.064914     0.08084"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_results.T.to_csv('result/result_yield_l_r2.csv', header=False)\n",
    "gen_results.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "003f2fe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>source</th>\n",
       "      <td>AI</td>\n",
       "      <td>AI2</td>\n",
       "      <td>Human</td>\n",
       "      <td>Random</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>Yield_CO_l</td>\n",
       "      <td>Yield_CO_l</td>\n",
       "      <td>Yield_CO_l</td>\n",
       "      <td>Yield_CO_l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run0</th>\n",
       "      <td>16.692978</td>\n",
       "      <td>19.028208</td>\n",
       "      <td>16.903599</td>\n",
       "      <td>18.192251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run1</th>\n",
       "      <td>17.633463</td>\n",
       "      <td>18.830437</td>\n",
       "      <td>17.366257</td>\n",
       "      <td>22.082722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run2</th>\n",
       "      <td>16.25412</td>\n",
       "      <td>18.712688</td>\n",
       "      <td>13.194419</td>\n",
       "      <td>15.549608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run3</th>\n",
       "      <td>15.352706</td>\n",
       "      <td>17.165209</td>\n",
       "      <td>19.826637</td>\n",
       "      <td>15.804123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run4</th>\n",
       "      <td>13.082523</td>\n",
       "      <td>15.209668</td>\n",
       "      <td>19.657354</td>\n",
       "      <td>16.252619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run5</th>\n",
       "      <td>15.649994</td>\n",
       "      <td>17.845213</td>\n",
       "      <td>16.265408</td>\n",
       "      <td>16.836199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run6</th>\n",
       "      <td>15.09106</td>\n",
       "      <td>16.518223</td>\n",
       "      <td>15.415771</td>\n",
       "      <td>16.9942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run7</th>\n",
       "      <td>18.369791</td>\n",
       "      <td>16.700026</td>\n",
       "      <td>14.308413</td>\n",
       "      <td>16.845404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run8</th>\n",
       "      <td>19.134571</td>\n",
       "      <td>19.475685</td>\n",
       "      <td>18.913168</td>\n",
       "      <td>18.710894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>run9</th>\n",
       "      <td>16.211351</td>\n",
       "      <td>16.433989</td>\n",
       "      <td>18.6073</td>\n",
       "      <td>19.492435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse_test_mean</th>\n",
       "      <td>16.347256</td>\n",
       "      <td>17.591934</td>\n",
       "      <td>17.045832</td>\n",
       "      <td>17.676044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse_test_max</th>\n",
       "      <td>19.134571</td>\n",
       "      <td>19.475685</td>\n",
       "      <td>19.826637</td>\n",
       "      <td>22.082722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse_test_min</th>\n",
       "      <td>13.082523</td>\n",
       "      <td>15.209668</td>\n",
       "      <td>13.194419</td>\n",
       "      <td>15.549608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rmse_test_std</th>\n",
       "      <td>1.654466</td>\n",
       "      <td>1.327102</td>\n",
       "      <td>2.149278</td>\n",
       "      <td>1.896514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         0           1           2           3\n",
       "source                  AI         AI2       Human      Random\n",
       "target          Yield_CO_l  Yield_CO_l  Yield_CO_l  Yield_CO_l\n",
       "run0             16.692978   19.028208   16.903599   18.192251\n",
       "run1             17.633463   18.830437   17.366257   22.082722\n",
       "run2              16.25412   18.712688   13.194419   15.549608\n",
       "run3             15.352706   17.165209   19.826637   15.804123\n",
       "run4             13.082523   15.209668   19.657354   16.252619\n",
       "run5             15.649994   17.845213   16.265408   16.836199\n",
       "run6              15.09106   16.518223   15.415771     16.9942\n",
       "run7             18.369791   16.700026   14.308413   16.845404\n",
       "run8             19.134571   19.475685   18.913168   18.710894\n",
       "run9             16.211351   16.433989     18.6073   19.492435\n",
       "rmse_test_mean   16.347256   17.591934   17.045832   17.676044\n",
       "rmse_test_max    19.134571   19.475685   19.826637   22.082722\n",
       "rmse_test_min    13.082523   15.209668   13.194419   15.549608\n",
       "rmse_test_std     1.654466    1.327102    2.149278    1.896514"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_results2.T.to_csv('result/result_yield_l_rmse.csv', header=False)\n",
    "gen_results2.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaab279",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
