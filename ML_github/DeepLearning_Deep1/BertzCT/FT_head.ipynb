{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69652f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\noton\\anaconda3\\envs\\Deep1\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\noton\\anaconda3\\envs\\Deep1\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:588: calling function (from tensorflow.python.eager.polymorphic_function.polymorphic_function) with experimental_relax_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "experimental_relax_shapes is deprecated, use reduce_retracing instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipped loading modules with pytorch-geometric dependency, missing a dependency. No module named 'dgl'\n",
      "Skipped loading some Jax models, missing a dependency. No module named 'haiku'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import deepchem as dc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, global_max_pool\n",
    "from torch_geometric.data import Batch, Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66bffaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GCNConv(30, 256)\n",
    "        self.conv2 = GCNConv(256, 256)\n",
    "        self.conv3 = GCNConv(256, 256)\n",
    "        self.conv4 = GCNConv(256, 256)\n",
    "        self.fc1 = nn.Linear(256, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 1)\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        #x = self.dropout(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv4(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = global_max_pool(x, data.batch)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "245051e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate(batch):\n",
    "    data_list, target_list = zip(*batch)\n",
    "    batch_data = Batch.from_data_list(data_list)\n",
    "    batch_target = torch.stack(target_list)\n",
    "    return batch_data, batch_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be45c11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_statistics(group):\n",
    "    r2_train = group['r2_train']\n",
    "    r2_test = group['r2_test']\n",
    "    return pd.Series({\n",
    "        'r2_train_mean': np.mean(r2_train),\n",
    "        'r2_train_std': np.std(r2_train, ddof=0),\n",
    "        'r2_test_mean': np.mean(r2_test),\n",
    "        'r2_test_std': np.std(r2_test, ddof=0)\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53851fc9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random State: 0\n",
      "Random State: 1\n",
      "Random State: 2\n",
      "Random State: 3\n",
      "Random State: 4\n",
      "Random State: 5\n",
      "Random State: 6\n",
      "Random State: 7\n",
      "Random State: 8\n",
      "Random State: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\noton\\AppData\\Local\\Temp\\ipykernel_8052\\428963382.py:113: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  gen_results = results_df.groupby(['source', 'target']).apply(calculate_statistics).reset_index()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>r2_train_mean</th>\n",
       "      <th>r2_train_std</th>\n",
       "      <th>r2_test_mean</th>\n",
       "      <th>r2_test_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AI</td>\n",
       "      <td>AATSC3d</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>1.694580e-05</td>\n",
       "      <td>0.393104</td>\n",
       "      <td>0.122804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AI</td>\n",
       "      <td>ABCGG</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>1.729131e-05</td>\n",
       "      <td>0.820846</td>\n",
       "      <td>0.035401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AI</td>\n",
       "      <td>ATSC3d</td>\n",
       "      <td>0.999975</td>\n",
       "      <td>5.389760e-05</td>\n",
       "      <td>0.464911</td>\n",
       "      <td>0.186683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AI</td>\n",
       "      <td>Kappa3</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>5.122426e-05</td>\n",
       "      <td>0.661523</td>\n",
       "      <td>0.067775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AI</td>\n",
       "      <td>VSA_EState3</td>\n",
       "      <td>0.999991</td>\n",
       "      <td>2.585985e-05</td>\n",
       "      <td>0.780217</td>\n",
       "      <td>0.061709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AI2</td>\n",
       "      <td>AATSC3d</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>3.691196e-05</td>\n",
       "      <td>0.370043</td>\n",
       "      <td>0.194534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AI2</td>\n",
       "      <td>ABCGG</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>6.522832e-06</td>\n",
       "      <td>0.728620</td>\n",
       "      <td>0.069755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AI2</td>\n",
       "      <td>ATSC3d</td>\n",
       "      <td>0.999973</td>\n",
       "      <td>6.730501e-05</td>\n",
       "      <td>0.325015</td>\n",
       "      <td>0.248287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AI2</td>\n",
       "      <td>Kappa3</td>\n",
       "      <td>0.999973</td>\n",
       "      <td>7.918324e-05</td>\n",
       "      <td>0.577607</td>\n",
       "      <td>0.098090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AI2</td>\n",
       "      <td>VSA_EState3</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>1.707336e-05</td>\n",
       "      <td>0.678309</td>\n",
       "      <td>0.116707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Human</td>\n",
       "      <td>AATSC3d</td>\n",
       "      <td>0.999830</td>\n",
       "      <td>3.521993e-04</td>\n",
       "      <td>0.330660</td>\n",
       "      <td>0.201813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Human</td>\n",
       "      <td>ABCGG</td>\n",
       "      <td>0.999958</td>\n",
       "      <td>8.619945e-05</td>\n",
       "      <td>0.654773</td>\n",
       "      <td>0.115103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Human</td>\n",
       "      <td>ATSC3d</td>\n",
       "      <td>0.999576</td>\n",
       "      <td>1.136088e-03</td>\n",
       "      <td>0.574697</td>\n",
       "      <td>0.135997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Human</td>\n",
       "      <td>Kappa3</td>\n",
       "      <td>0.999926</td>\n",
       "      <td>1.478115e-04</td>\n",
       "      <td>0.453019</td>\n",
       "      <td>0.224383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Human</td>\n",
       "      <td>VSA_EState3</td>\n",
       "      <td>0.999596</td>\n",
       "      <td>1.128447e-03</td>\n",
       "      <td>0.652177</td>\n",
       "      <td>0.119482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Random</td>\n",
       "      <td>AATSC3d</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>1.919270e-06</td>\n",
       "      <td>0.459789</td>\n",
       "      <td>0.109362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Random</td>\n",
       "      <td>ABCGG</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.372066e-07</td>\n",
       "      <td>0.875169</td>\n",
       "      <td>0.025022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Random</td>\n",
       "      <td>ATSC3d</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>2.204929e-06</td>\n",
       "      <td>0.552649</td>\n",
       "      <td>0.116840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Random</td>\n",
       "      <td>Kappa3</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>9.951943e-06</td>\n",
       "      <td>0.763371</td>\n",
       "      <td>0.041540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Random</td>\n",
       "      <td>VSA_EState3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.152557e-08</td>\n",
       "      <td>0.776483</td>\n",
       "      <td>0.067884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    source       target  r2_train_mean  r2_train_std  r2_test_mean  \\\n",
       "0       AI      AATSC3d       0.999993  1.694580e-05      0.393104   \n",
       "1       AI        ABCGG       0.999994  1.729131e-05      0.820846   \n",
       "2       AI       ATSC3d       0.999975  5.389760e-05      0.464911   \n",
       "3       AI       Kappa3       0.999983  5.122426e-05      0.661523   \n",
       "4       AI  VSA_EState3       0.999991  2.585985e-05      0.780217   \n",
       "5      AI2      AATSC3d       0.999987  3.691196e-05      0.370043   \n",
       "6      AI2        ABCGG       0.999998  6.522832e-06      0.728620   \n",
       "7      AI2       ATSC3d       0.999973  6.730501e-05      0.325015   \n",
       "8      AI2       Kappa3       0.999973  7.918324e-05      0.577607   \n",
       "9      AI2  VSA_EState3       0.999993  1.707336e-05      0.678309   \n",
       "10   Human      AATSC3d       0.999830  3.521993e-04      0.330660   \n",
       "11   Human        ABCGG       0.999958  8.619945e-05      0.654773   \n",
       "12   Human       ATSC3d       0.999576  1.136088e-03      0.574697   \n",
       "13   Human       Kappa3       0.999926  1.478115e-04      0.453019   \n",
       "14   Human  VSA_EState3       0.999596  1.128447e-03      0.652177   \n",
       "15  Random      AATSC3d       0.999999  1.919270e-06      0.459789   \n",
       "16  Random        ABCGG       1.000000  8.372066e-07      0.875169   \n",
       "17  Random       ATSC3d       0.999999  2.204929e-06      0.552649   \n",
       "18  Random       Kappa3       0.999996  9.951943e-06      0.763371   \n",
       "19  Random  VSA_EState3       1.000000  7.152557e-08      0.776483   \n",
       "\n",
       "    r2_test_std  \n",
       "0      0.122804  \n",
       "1      0.035401  \n",
       "2      0.186683  \n",
       "3      0.067775  \n",
       "4      0.061709  \n",
       "5      0.194534  \n",
       "6      0.069755  \n",
       "7      0.248287  \n",
       "8      0.098090  \n",
       "9      0.116707  \n",
       "10     0.201813  \n",
       "11     0.115103  \n",
       "12     0.135997  \n",
       "13     0.224383  \n",
       "14     0.119482  \n",
       "15     0.109362  \n",
       "16     0.025022  \n",
       "17     0.116840  \n",
       "18     0.041540  \n",
       "19     0.067884  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "epochs = 200\n",
    "lr = 1e-4\n",
    "wd = 1e-5\n",
    "\n",
    "results = []\n",
    "for random_state in range(10):\n",
    "    torch.manual_seed(0)\n",
    "    print(f'Random State: {random_state}')\n",
    "    \n",
    "    for d in [\"AI\", \"AI2\", \"Random\", \"Human\"]:\n",
    "        torch.manual_seed(0)\n",
    "        #print('Source : ', d)\n",
    "        dataset = d\n",
    "        \n",
    "        for c in [\"VSA_EState3\", \"Kappa3\", \"ABCGG\", \"AATSC3d\", \"ATSC3d\"]:\n",
    "            torch.manual_seed(0)\n",
    "            df = pd.read_csv('data_Real/data_real.csv')\n",
    "            smiles = df[\"SMILES\"]\n",
    "            featurizer = dc.feat.MolGraphConvFeaturizer(use_edges=True)\n",
    "            X = featurizer.featurize(smiles)\n",
    "            \n",
    "            y = df[c]\n",
    "            data_train, data_test, target_train, target_test = train_test_split(X, y, test_size=0.8, random_state=random_state)\n",
    "\n",
    "            target_train = scaler.fit_transform(target_train.values.reshape(-1, 1)).flatten()\n",
    "            target_test = scaler.transform(target_test.values.reshape(-1, 1)).flatten()\n",
    "            \n",
    "            target_train = torch.tensor(target_train, dtype=torch.float32)\n",
    "            target_test = torch.tensor(target_test, dtype=torch.float32)\n",
    "\n",
    "            data_train_list = []\n",
    "            for graph_data in data_train:\n",
    "                node_features = torch.tensor(graph_data.node_features, dtype=torch.float32)\n",
    "                edge_index = torch.tensor(graph_data.edge_index, dtype=torch.long)\n",
    "                edge_features = torch.tensor(graph_data.edge_features, dtype=torch.float32)\n",
    "                data = Data(x=node_features, edge_index=edge_index, edge_attr=edge_features)\n",
    "                data_train_list.append(data)\n",
    "\n",
    "            data_test_list = []\n",
    "            for graph_data in data_test:\n",
    "                node_features = torch.tensor(graph_data.node_features, dtype=torch.float32)\n",
    "                edge_index = torch.tensor(graph_data.edge_index, dtype=torch.long)\n",
    "                edge_features = torch.tensor(graph_data.edge_features, dtype=torch.float32)\n",
    "                data = Data(x=node_features, edge_index=edge_index, edge_attr=edge_features)\n",
    "                data_test_list.append(data)\n",
    "\n",
    "            train_loader = DataLoader(list(zip(data_train_list, target_train)), batch_size=len(data_train_list), collate_fn=custom_collate)\n",
    "            test_loader = DataLoader(list(zip(data_test_list, target_test)), batch_size=len(data_test_list), collate_fn=custom_collate)\n",
    "\n",
    "            model = Net()\n",
    "            model.load_state_dict(torch.load(f'data_{dataset}/model_{dataset}_sc.pth'))\n",
    "            \n",
    "            #ヘッドの更新をしない\n",
    "            #model.fc3 = nn.Linear(128, 1)\n",
    "        \n",
    "            model.train()\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "            criterion = nn.MSELoss()\n",
    "            \"\"\"\n",
    "            for param in model.conv1.parameters():\n",
    "                param.requires_grad = False\n",
    "            for param in model.conv2.parameters():\n",
    "                param.requires_grad = False\n",
    "            for param in model.conv3.parameters():\n",
    "                param.requires_grad = False\n",
    "            for param in model.conv4.parameters():\n",
    "                param.requires_grad = False\n",
    "            \"\"\"\n",
    "            device = torch.device('cpu')\n",
    "            model.to(device)\n",
    "\n",
    "            for epoch in range(epochs):\n",
    "                for data, target in train_loader:\n",
    "                    data = data.to(device)\n",
    "                    target = target.to(device)\n",
    "                    optimizer.zero_grad()\n",
    "                    out = model(data)\n",
    "                    loss = criterion(out, target.view(-1, 1))\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            model.eval()\n",
    "            pred_train = []\n",
    "            for data, target in train_loader:\n",
    "                data = data.to(device)\n",
    "                with torch.no_grad():\n",
    "                    out = model(data)\n",
    "                pred_train.append(out.cpu().numpy())\n",
    "            pred_train = np.concatenate(pred_train)\n",
    "\n",
    "            pred_test = []\n",
    "            for data, target in test_loader:\n",
    "                data = data.to(device)\n",
    "                with torch.no_grad():\n",
    "                    out = model(data)\n",
    "                pred_test.append(out.cpu().numpy())\n",
    "            pred_test = np.concatenate(pred_test)\n",
    "\n",
    "            pred_train = scaler.inverse_transform(pred_train)\n",
    "            pred_test = scaler.inverse_transform(pred_test)\n",
    "            target_train = scaler.inverse_transform(target_train.numpy().reshape(-1, 1)).flatten()\n",
    "            target_test = scaler.inverse_transform(target_test.numpy().reshape(-1, 1)).flatten()\n",
    "\n",
    "            r2_train_score = metrics.r2_score(target_train, pred_train)\n",
    "            r2_test_score = metrics.r2_score(target_test, pred_test)\n",
    "\n",
    "            results.append({'source': d, 'target': c, 'r2_train': r2_train_score, 'r2_test': r2_test_score})\n",
    "            #print(f'R2 test for {c} with random state {random_state}: {r2_test_score}')\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "gen_results = results_df.groupby(['source', 'target']).apply(calculate_statistics).reset_index()\n",
    "gen_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "463235ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_results.to_csv(f'result/RDKit_mordred/onestep_{epochs}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003f2fe5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
