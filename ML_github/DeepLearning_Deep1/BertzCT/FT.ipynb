{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69652f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\noton\\anaconda3\\envs\\Deep1\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\noton\\anaconda3\\envs\\Deep1\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:588: calling function (from tensorflow.python.eager.polymorphic_function.polymorphic_function) with experimental_relax_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "experimental_relax_shapes is deprecated, use reduce_retracing instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipped loading modules with pytorch-geometric dependency, missing a dependency. No module named 'dgl'\n",
      "Skipped loading some Jax models, missing a dependency. No module named 'haiku'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import deepchem as dc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, global_max_pool\n",
    "from torch_geometric.data import Batch, Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66bffaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#モデルの定義。事前学習の際はドロップアウトを入れていなかったが、ファインチューニングの際は入れたほうがよさそうであった。\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GCNConv(30, 256)\n",
    "        self.conv2 = GCNConv(256, 256)\n",
    "        self.conv3 = GCNConv(256, 256)\n",
    "        self.conv4 = GCNConv(256, 256)\n",
    "        self.fc1 = nn.Linear(256, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 1)\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        #x = self.dropout(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv4(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = global_max_pool(x, data.batch)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "245051e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate(batch):\n",
    "    data_list, target_list = zip(*batch)\n",
    "    batch_data = Batch.from_data_list(data_list)\n",
    "    batch_target = torch.stack(target_list)\n",
    "    return batch_data, batch_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be45c11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_statistics(group):\n",
    "    r2_train = group['r2_train']\n",
    "    r2_test = group['r2_test']\n",
    "    return pd.Series({\n",
    "        'r2_train_mean': np.mean(r2_train),\n",
    "        'r2_train_std': np.std(r2_train, ddof=0),\n",
    "        'r2_test_mean': np.mean(r2_test),\n",
    "        'r2_test_std': np.std(r2_test, ddof=0)\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53851fc9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random State: 0\n",
      "Random State: 1\n",
      "Random State: 2\n",
      "Random State: 3\n",
      "Random State: 4\n",
      "Random State: 5\n",
      "Random State: 6\n",
      "Random State: 7\n",
      "Random State: 8\n",
      "Random State: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\noton\\AppData\\Local\\Temp\\ipykernel_10744\\3009726413.py:116: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  gen_results = results_df.groupby(['source', 'target']).apply(calculate_statistics).reset_index()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>r2_train_mean</th>\n",
       "      <th>r2_train_std</th>\n",
       "      <th>r2_test_mean</th>\n",
       "      <th>r2_test_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AI</td>\n",
       "      <td>AATSC3d</td>\n",
       "      <td>0.999960</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.512213</td>\n",
       "      <td>0.127507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AI</td>\n",
       "      <td>ABCGG</td>\n",
       "      <td>0.998999</td>\n",
       "      <td>0.001483</td>\n",
       "      <td>0.784511</td>\n",
       "      <td>0.056914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AI</td>\n",
       "      <td>ATSC3d</td>\n",
       "      <td>0.999473</td>\n",
       "      <td>0.000681</td>\n",
       "      <td>0.638515</td>\n",
       "      <td>0.082805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AI</td>\n",
       "      <td>Kappa3</td>\n",
       "      <td>0.997667</td>\n",
       "      <td>0.004478</td>\n",
       "      <td>0.515800</td>\n",
       "      <td>0.148313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AI</td>\n",
       "      <td>VSA_EState3</td>\n",
       "      <td>0.998543</td>\n",
       "      <td>0.003964</td>\n",
       "      <td>0.773168</td>\n",
       "      <td>0.066017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AI2</td>\n",
       "      <td>AATSC3d</td>\n",
       "      <td>0.999851</td>\n",
       "      <td>0.000384</td>\n",
       "      <td>0.363568</td>\n",
       "      <td>0.219646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AI2</td>\n",
       "      <td>ABCGG</td>\n",
       "      <td>0.997288</td>\n",
       "      <td>0.004956</td>\n",
       "      <td>0.612367</td>\n",
       "      <td>0.115963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AI2</td>\n",
       "      <td>ATSC3d</td>\n",
       "      <td>0.999897</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.447848</td>\n",
       "      <td>0.269566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AI2</td>\n",
       "      <td>Kappa3</td>\n",
       "      <td>0.999459</td>\n",
       "      <td>0.000772</td>\n",
       "      <td>0.243034</td>\n",
       "      <td>0.198231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AI2</td>\n",
       "      <td>VSA_EState3</td>\n",
       "      <td>0.998568</td>\n",
       "      <td>0.003984</td>\n",
       "      <td>0.683380</td>\n",
       "      <td>0.110975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Human</td>\n",
       "      <td>AATSC3d</td>\n",
       "      <td>0.999936</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.454599</td>\n",
       "      <td>0.233172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Human</td>\n",
       "      <td>ABCGG</td>\n",
       "      <td>0.998353</td>\n",
       "      <td>0.002766</td>\n",
       "      <td>0.519504</td>\n",
       "      <td>0.101201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Human</td>\n",
       "      <td>ATSC3d</td>\n",
       "      <td>0.999608</td>\n",
       "      <td>0.000634</td>\n",
       "      <td>0.535998</td>\n",
       "      <td>0.183078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Human</td>\n",
       "      <td>Kappa3</td>\n",
       "      <td>0.997459</td>\n",
       "      <td>0.003140</td>\n",
       "      <td>0.242065</td>\n",
       "      <td>0.235097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Human</td>\n",
       "      <td>VSA_EState3</td>\n",
       "      <td>0.998377</td>\n",
       "      <td>0.004010</td>\n",
       "      <td>0.717274</td>\n",
       "      <td>0.111984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Random</td>\n",
       "      <td>AATSC3d</td>\n",
       "      <td>0.999846</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>0.526267</td>\n",
       "      <td>0.112793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Random</td>\n",
       "      <td>ABCGG</td>\n",
       "      <td>0.999521</td>\n",
       "      <td>0.000886</td>\n",
       "      <td>0.845760</td>\n",
       "      <td>0.038527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Random</td>\n",
       "      <td>ATSC3d</td>\n",
       "      <td>0.999472</td>\n",
       "      <td>0.000991</td>\n",
       "      <td>0.637885</td>\n",
       "      <td>0.077066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Random</td>\n",
       "      <td>Kappa3</td>\n",
       "      <td>0.999186</td>\n",
       "      <td>0.001522</td>\n",
       "      <td>0.714798</td>\n",
       "      <td>0.077080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Random</td>\n",
       "      <td>VSA_EState3</td>\n",
       "      <td>0.998720</td>\n",
       "      <td>0.003397</td>\n",
       "      <td>0.790173</td>\n",
       "      <td>0.072233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    source       target  r2_train_mean  r2_train_std  r2_test_mean  \\\n",
       "0       AI      AATSC3d       0.999960      0.000058      0.512213   \n",
       "1       AI        ABCGG       0.998999      0.001483      0.784511   \n",
       "2       AI       ATSC3d       0.999473      0.000681      0.638515   \n",
       "3       AI       Kappa3       0.997667      0.004478      0.515800   \n",
       "4       AI  VSA_EState3       0.998543      0.003964      0.773168   \n",
       "5      AI2      AATSC3d       0.999851      0.000384      0.363568   \n",
       "6      AI2        ABCGG       0.997288      0.004956      0.612367   \n",
       "7      AI2       ATSC3d       0.999897      0.000155      0.447848   \n",
       "8      AI2       Kappa3       0.999459      0.000772      0.243034   \n",
       "9      AI2  VSA_EState3       0.998568      0.003984      0.683380   \n",
       "10   Human      AATSC3d       0.999936      0.000099      0.454599   \n",
       "11   Human        ABCGG       0.998353      0.002766      0.519504   \n",
       "12   Human       ATSC3d       0.999608      0.000634      0.535998   \n",
       "13   Human       Kappa3       0.997459      0.003140      0.242065   \n",
       "14   Human  VSA_EState3       0.998377      0.004010      0.717274   \n",
       "15  Random      AATSC3d       0.999846      0.000259      0.526267   \n",
       "16  Random        ABCGG       0.999521      0.000886      0.845760   \n",
       "17  Random       ATSC3d       0.999472      0.000991      0.637885   \n",
       "18  Random       Kappa3       0.999186      0.001522      0.714798   \n",
       "19  Random  VSA_EState3       0.998720      0.003397      0.790173   \n",
       "\n",
       "    r2_test_std  \n",
       "0      0.127507  \n",
       "1      0.056914  \n",
       "2      0.082805  \n",
       "3      0.148313  \n",
       "4      0.066017  \n",
       "5      0.219646  \n",
       "6      0.115963  \n",
       "7      0.269566  \n",
       "8      0.198231  \n",
       "9      0.110975  \n",
       "10     0.233172  \n",
       "11     0.101201  \n",
       "12     0.183078  \n",
       "13     0.235097  \n",
       "14     0.111984  \n",
       "15     0.112793  \n",
       "16     0.038527  \n",
       "17     0.077066  \n",
       "18     0.077080  \n",
       "19     0.072233  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "epochs = 200\n",
    "lr = 1e-4\n",
    "wd = 1e-5\n",
    "\n",
    "results = []\n",
    "for random_state in range(10):\n",
    "    torch.manual_seed(0)\n",
    "    print(f'Random State: {random_state}')\n",
    "    \n",
    "    for d in [\"AI\", \"AI2\", \"Random\", \"Human\"]:\n",
    "        torch.manual_seed(0)\n",
    "        #print('Source : ', d)\n",
    "        dataset = d\n",
    "        \n",
    "        for c in [\"VSA_EState3\", \"Kappa3\", \"ABCGG\", \"AATSC3d\", \"ATSC3d\"]:\n",
    "            torch.manual_seed(0)\n",
    "            \n",
    "            #実在分子データのロード及びグラフ特徴量の生成\n",
    "            df = pd.read_csv('data_Real/data_real.csv')\n",
    "            smiles = df[\"SMILES\"]\n",
    "            featurizer = dc.feat.MolGraphConvFeaturizer(use_edges=True)\n",
    "            X = featurizer.featurize(smiles)\n",
    "            \n",
    "            #ターゲットのスケールが事前学習の際と違うので、ターゲットもスケーリングする\n",
    "            y = df[c]\n",
    "            data_train, data_test, target_train, target_test = train_test_split(X, y, test_size=0.8, random_state=random_state)\n",
    "\n",
    "            target_train = scaler.fit_transform(target_train.values.reshape(-1, 1)).flatten()\n",
    "            target_test = scaler.transform(target_test.values.reshape(-1, 1)).flatten()\n",
    "            \n",
    "            target_train = torch.tensor(target_train, dtype=torch.float32)\n",
    "            target_test = torch.tensor(target_test, dtype=torch.float32)\n",
    "\n",
    "            data_train_list = []\n",
    "            for graph_data in data_train:\n",
    "                node_features = torch.tensor(graph_data.node_features, dtype=torch.float32)\n",
    "                edge_index = torch.tensor(graph_data.edge_index, dtype=torch.long)\n",
    "                edge_features = torch.tensor(graph_data.edge_features, dtype=torch.float32)\n",
    "                data = Data(x=node_features, edge_index=edge_index, edge_attr=edge_features)\n",
    "                data_train_list.append(data)\n",
    "\n",
    "            data_test_list = []\n",
    "            for graph_data in data_test:\n",
    "                node_features = torch.tensor(graph_data.node_features, dtype=torch.float32)\n",
    "                edge_index = torch.tensor(graph_data.edge_index, dtype=torch.long)\n",
    "                edge_features = torch.tensor(graph_data.edge_features, dtype=torch.float32)\n",
    "                data = Data(x=node_features, edge_index=edge_index, edge_attr=edge_features)\n",
    "                data_test_list.append(data)\n",
    "\n",
    "            train_loader = DataLoader(list(zip(data_train_list, target_train)), batch_size=len(data_train_list), collate_fn=custom_collate)\n",
    "            test_loader = DataLoader(list(zip(data_test_list, target_test)), batch_size=len(data_test_list), collate_fn=custom_collate)\n",
    "            \n",
    "            #モデルの定義及び事前学習パラメータのロード\n",
    "            model = Net()\n",
    "            model.load_state_dict(torch.load(f'data_{dataset}/model_{dataset}_sc.pth'))\n",
    "            \n",
    "            #ヘッドの更新\n",
    "            model.fc3 = nn.Linear(128, 1)\n",
    "            \n",
    "            #訓練\n",
    "            model.train()\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "            criterion = nn.MSELoss()\n",
    "            \n",
    "            #層はすべて解凍状態。以下をFalseに設定すると該当する層が凍結状態になる\n",
    "            \"\"\"\n",
    "            for param in model.conv1.parameters():\n",
    "                param.requires_grad = False\n",
    "            for param in model.conv2.parameters():\n",
    "                param.requires_grad = False\n",
    "            for param in model.conv3.parameters():\n",
    "                param.requires_grad = False\n",
    "            for param in model.conv4.parameters():\n",
    "                param.requires_grad = False\n",
    "            \"\"\"\n",
    "            device = torch.device('cpu')\n",
    "            model.to(device)\n",
    "\n",
    "            for epoch in range(epochs):\n",
    "                for data, target in train_loader:\n",
    "                    data = data.to(device)\n",
    "                    target = target.to(device)\n",
    "                    optimizer.zero_grad()\n",
    "                    out = model(data)\n",
    "                    loss = criterion(out, target.view(-1, 1))\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "            \n",
    "            #テスト\n",
    "            model.eval()\n",
    "            pred_train = []\n",
    "            for data, target in train_loader:\n",
    "                data = data.to(device)\n",
    "                with torch.no_grad():\n",
    "                    out = model(data)\n",
    "                pred_train.append(out.cpu().numpy())\n",
    "            pred_train = np.concatenate(pred_train)\n",
    "\n",
    "            pred_test = []\n",
    "            for data, target in test_loader:\n",
    "                data = data.to(device)\n",
    "                with torch.no_grad():\n",
    "                    out = model(data)\n",
    "                pred_test.append(out.cpu().numpy())\n",
    "            pred_test = np.concatenate(pred_test)\n",
    "\n",
    "            pred_train = scaler.inverse_transform(pred_train)\n",
    "            pred_test = scaler.inverse_transform(pred_test)\n",
    "            target_train = scaler.inverse_transform(target_train.numpy().reshape(-1, 1)).flatten()\n",
    "            target_test = scaler.inverse_transform(target_test.numpy().reshape(-1, 1)).flatten()\n",
    "\n",
    "            r2_train_score = metrics.r2_score(target_train, pred_train)\n",
    "            r2_test_score = metrics.r2_score(target_test, pred_test)\n",
    "\n",
    "            results.append({'source': d, 'target': c, 'r2_train': r2_train_score, 'r2_test': r2_test_score})\n",
    "            #print(f'R2 test for {c} with random state {random_state}: {r2_test_score}')\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "gen_results = results_df.groupby(['source', 'target']).apply(calculate_statistics).reset_index()\n",
    "gen_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "463235ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_results.to_csv(f'result/RDKit_mordred/onestep_{epochs}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003f2fe5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
